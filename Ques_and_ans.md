

## 1. 网络

#### IPV4跟IPV6比较

1. IPv4：



2. IPv6：

地址长度是128位，每16位是一组，中间用冒号‘：’隔开；连续的0可以用两个冒号来折叠，但只能用一次；

亮点：

- IPv6可以自动设置，即使没有DHCP服务也可以实现IP地址的自动分配；
- IPv6 包头包首部长度采用固定的值 `40` 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大**提高了传输的性能**。
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**。

#### 网桥工作在哪一层

- 物理层：双绞线、中继器、集线器
- 数据链路层：网桥、交换机（根据MAC地址寻址）、网卡
- 网络层：路由器（根据IP地址寻址）
- 应用层：网关；

**网桥**工作在数据链路层的介质访问控制(MAC)子层上,用于在多个使用同一种通信协议的网段中传送数据包的设备

#### 网关的作用是什么

网关（Gateway）又称网间连接器、协议转换器。网关在传输层上以实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关的结构也和路由器类似，不同的是互连层。网关既可以用于广域互连，也可以用于局域网互连。网关是一种充当转换重任的计算机系统或设备。在使用不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关也可以提供过滤和安全功能。大多数网关运行在OSI 7层协议的顶层–应用层。

那么网关到底是什么呢？网关实质上是一个网络通向其他网络的IP地址。比如有网络A和网络B，网络A的IP地址范围为`192.168.1.1~192.168.1.254`，子网掩码为`255.255.255.0`；网络B的IP地址范围为`192.168.2.1~192.168.2.254`，子网掩码为`255.255.255.0`。在没有路由器的情况下，两个网络之间是不能进行TCP/IP通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP协议也会根据子网掩码（`255.255.255.0`）判定两个网络中的主机处在不同的网络里。而要实现这两个网路之间的通信，则必须通过网关。如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机。

默认网关的意思是一台主机如果找不到可用的网关，就把数据包发给默认指定的网关，由这个网关来处理数据包。

#### 子网掩码详细作用？

主要是用来区分网络地址与主机地址；如果网络地址相同，则证明是在同一个网段，如果不同则需要借助路由的转发；

是由于IPv4的地址资源紧缺，做不到每个网络设备都能获得一个网络地址。可变长度的网络地址分配方式相比以前主类网络划分方式更加灵活，在有限的网址资源的情况下，提高网络地址的利用率，减少网络地址的浪费。而灵活的代价就是：网络地址可以改变长度，没有规律可循了，只能靠子网掩码来划分了，所以这就是子网掩码的用途：**区分网络地址和主机地址。**

在没有子网掩码之前，网络地址按照主类网络的方式进行区分，但是这种划分方式不够灵活，也很浪费地址资源，并且随着通信设备的普及，有上网需求的通信设备不断增加，并且online和offline之间的切换频繁，数量是随着时间变化而变化的。因此子网掩码的出现，在**划分地址资源**方面做出了改进。

#### OSI七层协议

分别是-物理层、数据链路层、网络层、传输层、会话层、表示层、应用层；

- 应用层：为应用程序提供服务；
  - FTP(21端口)：文件传输协议
  - SSH(22端口)：远程登陆
  - TELNET(23端口)：远程登录
  - SMTP(25端口)：发送邮件
  - POP3(110端口)：接收邮件
  - HTTP(80端口)：超文本传输协议
  - DNS(53端口)：运行在UDP上，域名解析服务
- 表示层：数据格式转化、数据加密；
- 会话层：建立、管理和维护会话；
- 传输层：建立、管理和维护端到端的连接；
- 网络层：IP选址与路由选择；
- 数据链路层：提供介质访问与链路管理；
- 物理层：通过物理介质传输比特流；

#### Get 与 Post区别？

- **GET**用于获取资源，**POST**用于传输实体主体；

- **参数方面：**GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具查看。因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 `中文` 会转换为 `%E4%B8%AD%E6%96%87`，而`空格`会转换为 `%20`。POST 参数支持标准字符集。

- **安全方面：**安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。

  安全的方法除了 GET 之外还有：HEAD、OPTIONS。

  不安全的方法除了 POST 之外还有 PUT、DELETE。

- **幂等性：**幂等性：同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。所有的安全的方法都是幂等的，在正确实现的情况下：GET、HEAD、PUT、DELETE等是幂等的，POST是非幂等的；

- **可缓存：**如果要对响应进行缓存，需要满足以下条件：

  - 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。
  - 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。
  - 响应报文的 Cache-Control 首部字段没有指定不进行缓存。

- 为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest：

  > XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。

  - 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。
  - 而 GET 方法 Header 和 Data 会一起发送。

#### Http与Https区别？

1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；
2. HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；
3. HTTPS由于加密解密会带来更大的CPU和内存开销；
4. HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买

#### HTTPS加密过程？

- 加密：
  - 对称密钥加密：对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。所以运算速度会非常快，但是无法安全的将密钥传输给通信方；
  - 非对称密钥加密：非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。
  - 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）
- HTTPS 采用混合的加密机制：
  - 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性;
  - 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key）
- 数字签名：
  - 非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。

#### Https的连接过程 *

1. 客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；
2. 服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，**加密公钥**（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；
3. 客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；
4. 如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个**随机密钥**（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行**摘要**计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；
5. 服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；
6. 浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密

总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。

#### HTTP的状态码

| 状态码 | 类别                             | 含义                       |
| ------ | -------------------------------- | -------------------------- |
| 1XX    | Informational（信息性状态码）    | 接收的请求正在处理         |
| 2XX    | Success（成功状态码）            | 请求正常处理完毕           |
| 3XX    | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 |
| 4XX    | Client Error（客户端错误状态码） | 服务器无法处理请求         |
| 5XX    | Server Error（服务器错误状态码） | 服务器处理请求出错         |

#### HTTP使用长连接有哪些优点？

- 减少握手的次数；
- 减少慢启动的影响；短链接的话要每一个连接都要经历从慢到快的那个过程，总体上时间要慢得多；
- 缺点：会有队头阻塞的问题，如果中间某个数据包丢失，那么即使后面的数据包传送过去了，接收端也不能够接收；

#### TLS/SSL协议是怎样保障信息安全的？

- PKI证书体系；
- 密钥交换协议；椭圆曲线
- 对称加密算法； 

#### HTTP2.0协议有哪些优点？

- HTTP1.1 的缺点：header太长了、长连接的情况下不支持多路复用；
- 多路复用、消息推送：把关联性的消息直接推送，
- header的编码：HPACK编码（动态表、静态表、静态Huffman、整数编码）
- stream优先级：父子依赖、权重

#### TCP\UDP的区别

1. TCP是面向连接的，UDP是无连接的；
2. TCP是可靠的，UDP不可靠；
3. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；
4. TCP是面向字节流的，UDP是面向报文的；
5. TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；
6. TCP首部开销（20字节）比UDP首部开销（8字节）要大；
7. UDP 的主机不需要维持复杂的连接状态表；

#### TCP为什么可靠

1. 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；
2. 对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；
3. 丢弃重复数据：对于重复数据，能够丢弃重复数据；
4. 应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；
5. 超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
6. 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

#### TCP三次握手

![三次握手.png-12.4kB](http://static.zybuluo.com/Rico123/c7m5fo6qdua0q7me88jm9w10/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png)

- 第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；
- 第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；
- 第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。

>TCP连接可以两次握手吗？

不可以，两方面的原因：

1. 可能会出现已经失效的连接请求报文段又发送到了服务端，比如说client发送的一个连接请求报文段在传输过程中并没有丢失，而是在某个网络节点拥塞并滞留了一段时间， 导致报文段延误到连接释放之后才到达服务器，这样服务器收到了一个原本是失效的报文段，但是服务器不知道，会误认为是client发送的新的连接请求，所以就会向client发送确认报文段建立连接，如果是两次握手，那么现在就成功建立了连接，但实际client端并没有发送新的建立连接的请求，也就不会理睬服务器的确认报文段，不会向服务器发送数据。而服务器端以为已经建立好了连接，就会一直等待client发送数据，导致服务器资源的浪费；三次握手就可以解决这样的问题，在client收到服务器确认报文段时，不会向服务器的确认发送确认，服务器收不到确认，连接也就不能建立；
2. 两次握手无法保证client正确的收到服务器发送的确认报文，也无法保证client与服务器端之间成功交换初始序列号；

> 可以采用四次握手吗？

- 可以，但是三次握手可以搞定的事情，用四次握手才搞定，就会降低传输的效率；多出来的一次是将第二次服务器到客户端的确认报文拆分为两次传输，第一次服务器只发送ACK与acknowledge number的确认报文段，而服务器端的SYN与初始序列号在第三次握手的时候发送；

> 第三次握手中，如果客户端的ACK报文段没有成功发送到服务器端，会发生什么？

- 服务器端：由于没有收到ACK确认，会重复发送第二次握手的报文段，（默认是重发5次，然后会自动关闭连接，进入closed状态），在客户端收到重发的报文段后会重新传ACK给服务器端；
- 客户端：1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态；2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。

> 建立连接后，如果客户端出现了故障会怎么样？

- 服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

> 什么是初始序列号？

- TCP连接的一方，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），以该序列号为原点，对要传送的数据进行编号. 三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节。

#### TCP四次挥手

- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入**FIN_WAIT_1**状态；
- 第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入**CLOSE_WAIT**状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据，客户端进入**FIN_WAIT_2**的状态。
- 第三次挥手：Server将FIN置1，发送一个序列号给Client，进入**LAST_ACK**状态，客户端进入**TIME_WAIT**状态；
- 第四次挥手：Client收到服务器的FIN后，进入**TIME_WAIT**状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为**CLOSED**状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入**CLOSED**状态。完成四次挥手。

> 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？

- 因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。
- close_wait可以存在的时间可以非常的长，因为TCP允许全双工，可以进入半打开的状态；只有一端可以发消息，另一端不可以发了，这个时候就会进入closed_wait的状态；当然实际情况下，长时间使用这种状态的连接是很少的，当用netstate命令看到了close_wait，一半以上就是出bug了；

> 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

- 客户端没有收到ACK确认，会重新发送FIN请求。

> 客户端TIME_WAIT状态的意义是什么？

- 第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。
- MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

#### TCP滑动窗口机制

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。

发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

> 接收窗口为0会怎么样？零窗口

- 如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。

#### TCP拥塞控制机制

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

TCP 主要通过四个算法来进行拥塞控制：`慢开始、拥塞避免、快重传、快恢复`。

发送方需要维护一个叫做**拥塞窗口（cwnd）**的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。

为了便于讨论，做如下假设：

- 接收方有足够大的接收缓存，因此不会发生流量控制；
- 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。

1. 慢开始与拥塞避免

发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

2. 快重传与快恢复

在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。

在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。

在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

#### TCP和UDP分别对应的常见应用层协议

1). TCP对应的应用层协议

- FTP：定义了文件传输协议，使用21端口。常说某某计算机开了FTP服务便是启动了文件传输服务。下载文件，上传主页，都要用到FTP服务。
- Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于DOS模式下的通信服务。如以前的BBS是-纯字符界面的，支持BBS的服务器将23端口打开，对外提供服务。
- SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么SMTP端口设置这个栏，服务器开放的是25号端口。
- POP3：它是和SMTP对应，POP3用于接收邮件。通常情况下，POP3协议所用的是110端口。也是说，只要你有相应的使用POP3协议的程序（例如Fo-xmail或Outlook），就可以不以Web方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。
- HTTP：从Web服务器传输超文本到本地浏览器的传送协议。

2). UDP对应的应用层协议

- DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。
- SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。
- TFTP(Trival File Transfer Protocal)：简单文件传输协议，该协议在熟知端口69上使用UDP服务。

#### URL请求到渲染的过程

浏览器解析URL->生成发送给Web服务器的请求信息（HTTP请求信息）->查询服务器域名对应的IP地址（DNS）-> 发起client到server的连接请求（TCP三次握手） -> 连接建立之后由client向server发送HTTP请求信息 -> 服务器处理请求信息，并将结果返回给浏览器 -> 浏览器完成解析并渲染

1. 浏览器解析URL，先要通过网站的域名查询域名对应的IP地址；
2. 生成DNS查询报文，并放入目的地址为DNS服务器IP地址的IP数据报中，IP数据报放入以太网帧中，如果这时还不知道网关的MAC地址，可能还需要ARP协议的帮助来获取网关的MAC地址；
3. 收到来自DNS服务器的应答报文之后，解析出域名地址对应的IP地址；
4. 有了HTTP服务器的IP地址之后，主机通过TCP三次握手来与HTTP服务器建立连接；
5. 主机生成TCP套接字，并且生成HTTP GET报文，发送给HTTP服务器；
6. HTTP服务器从TCP套接字读取GET报文，生成一个HTTP响应报文，返回给浏览器；
7. 浏览器收到HTTP响应报文后，解析内容后进行渲染，显示出相应的Web页面；

#### DNS协议

DNS域名解析协议就是将域名地址转换为IP地址；

域名层级之间靠句点`"."`来分割，越靠右边的域名层级越高；

- 域名层级关系：
  - 根DNS服务器
  - 顶级域DNS服务器
  - 权威DNS服务器
- 工作流程：
  - 客户端发送DNS请求，发送给本地DNS服务器；
  - 本地域名服务器：如果能够在缓存表中找到域名的IP地址，则直接返回IP地址；如果没有，本地DNS会发送信息到根域名服务器；
  - 根DNS服务器：根据域名给出顶级域名服务器地址，并发送给本地域名服务器；
  - 本地域名服务器收到地址后发送信息给顶级域名服务器；
  - 顶级域名服务器将权威域名服务器地址发送给本地域名服务器；
  - 本地域名服务器发送信息给权威域名服务器；
  - 权威域名服务器将IP地址发送给本地域名服务器；
  - 本地域名服务器将IP地址返回给客户端；

#### ARP协议

ARP 地址解析协议，作用是在以太网环境中，数据的传输所依懒的是`MAC地址`而非`IP地址`，而将已知`IP地址`转换为`MAC地址`的工作是由`ARP协议`来完成的。每个主机都会有一个`ARP高速缓存`，里面有所在的局域网上的各主机和路由器的IP地址到硬件地址的`映射表`。

数据包在确定源IP地址与目的IP地址之后，会通过主机的路由表来确定数据包的下一跳的IP地址，但是数据链路层需要的是下一跳的MAC地址，因此借助ARP协议可以完成IP地址到MAC地址的转换，具体过程如下：

- ARP协议借助ARP请求与ARP响应两种包来确定MAC地址；
- 主机通过广播发送ARP请求包，包中含有想知道的MAC地址对应的IP地址；
- 同链路中设备收到ARP请求包后将会解析ARP请求包中的目标IP地址，如果匹配将会返回含有自己MAC地址的ARP响应包给主机；
- 操作系统会建立一个所在局域网上各设备的IP地址到MAC地址的映射表，并会定期清理映射表中的内容；

> RARP协议：ARP协议的逆协议，作用是根据MAC地址转换为IP地址；
>
> 如果是小型嵌入式设备接入网络，则通常需要一台RARP服务器来协助其完成IP设置，服务器中注册该设备的MAC地址与IP地址，然后将该设备接入网络，随后就会发送一条MAC地址到IP地址的RARP请求包，服务器则会将查询到的IP地址通过相应包发送给设备，协助其完成IP地址设置；

#### ICMP协议

ICMP(internet control message protocol)网际控制报文协议，目的是提高IP数据报交付成功的机会。ICMP属于IP层协议，允许主机或路由器报告差错情况和提供有关异常情况的报告，测试网络层有没有故障。

功能：确认IP包是否成功送达目标地址、报告发送过程中IP包被废弃的原因、改善网络设置等；

1. ICMP报文格式

> 首先，ICMP报文是封装在IP包里面的，作为IP包的数据部分存在，是TCP/IP协议中IP协议的助手；

类型（8位）：ICMP查询报文（用于诊断）、ICMP差错报告报文（通知出错原因）

```c++
/*
查询报文类型：<类型号-内容>   0-回送应答、8-回送请求

类型号（8位）：0、8;
代码（8位）：0;
校验和（16位）：
标识符（16位）：用以区分是哪个进程发送的ICMP包，比如使用进程PID作为标识符;
序号（16位）：序号从0开始，每发送一次新的回送请求就会加1，可以用来确认网络包是否有丢失;
选项数据：具体情况而定，ping会存放发送请求的时间，来计算往返时间；
```

```c++
/*
差错报文类型：<类型号-内容>   3-目标不可达、4-原点抑制、5-重定向或改变路由、11-超时

类型号（8位）：3、4、5、11

//类型号 3 目标不可达消息
IP路由器无法将IP数据包发送给目标地址时，返回发送端主机一个目标不可达的ICMP消息
 在ICMP包头的代码字段中记录具体不可达原因；
 0-网络不可达；
 1-主机不可达；
 2-协议不可达；
 3-端口不可达；
 4-需要进行分片但设置了不分片；
//类型号 4 原点抑制消息
ICMP原点抑制是为了缓解低速广域线路下，路由器可能会遇到网络拥堵的问题；
 具体来说就是当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向IP包的源地址发送一个ICMP原点抑制消息；收到该包的主机会增大IP包的传输间隔，减少网络拥堵的状况；
//类型号 5 重定向消息
如果路由器发现发送端使用了非最优路径发送数据，它会返回一个ICMP重定向消息给主机；
 消息中包含最合适的路由信息和源数据；
//类型号 11 超时消息
如果IP包中的TTL值在当前路由器中减为0，则该IP包被丢弃，并且发送一个ICMP超时消息给发送端主机；
```

2. ping的过程：

1. 源主机先构建一个ICMP回送请求消息数据包，类型号为8，并且还有序号，每发一个请求数据包，序号自动加1，并且在报文数据部分插入发送时间，以方便计算往返时间RTT；
2. 由ICMP协议将数据包与目的IP地址交给IP层，IP层构建一个协议字段为1的IP数据包；
3. 从本地ARP映射表中查询或者利用ARP协议查询目的MAC地址，通过数据链路层构建一个数据帧并发送出去；

4. 目的端收到数据帧后，查验目的MAC地址，匹配则接收，否则丢弃；
5. 提取数据帧中的IP数据包，IP层检查后将有用的信息提取交给ICMP协议；
6. 目的端主机会构建一个ICMP回送响应消息数据包，类型为0，序号为请求数据包中的序号，发送给源端主机；

- 源端如果在规定时间内没有收到ICMP应答包，则说明目标主机不可达，收到应答包后，会用当前时刻减去数据包发送时刻，得到数据包的延迟；

3. traceroute的作用：

1. 通过故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器；
2. 利用traceroute可以知道发出的UDP包是否到达了目的主机；
3. traceroute可以通过故意设置不分片，来确定路径的MTU；

#### IGMP协议



#### DHCP协议

DHCP协议用于动态获取IP地址；具体步骤为：（本部分来自小林coding）

- 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 `255.255.255.255`（端口 67） 并且使用` 0.0.0.0`（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
- DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 `255.255.255.255`，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
- 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST）**进行响应，回显配置的参数。
- 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

- 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

所以在DHCP 交互中**全程都是使用 UDP 广播通信**。

> 对于客户端与DHCP服务器不在同一局域网内的情况，需要用到DHCP中继代理：
>
> - DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
> - 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包转发给 DHCP 客户端 。
>
> 因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址。

#### 客户端不断进行请求链接会怎样？DDos攻击

1)、DDos 攻击

- 客户端向服务端发送请求链接数据包
- 服务端向客户端发送确认数据包
- 客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认

2)、DDos 预防 **( 没有彻底根治的办法，除非不使用TCP )**

- 限制同时打开SYN半链接的数目
- 缩短SYN半链接的Time out 时间
- 关闭不必要的服务

------

## 2. 操作系统

#### 进程与线程的区别是啥

- 进程：进程是系统进行资源分配的基本单位，进程的基本信息与状态由进程控制块PCB来描述；

  - 程序 = 算法 + 数据结构（描述进程的数据结构：进程控制块PCB） 

- 线程：线程是CPU调度的基本单位，是进程当中的一条执行流程，同时线程依赖于进程存在，一个进程至少有一个线程存在；`线程=进程-共享资源`

  - 线程能够减少并发执行的时间和空间开销：
    - 线程的创建时间比进程短；
    - 线程的终止时间比进程短
    - 同一进程内的线程切换时间比进程短
    - 由于同一进程的各线程之间共享内存和文件资源，可直接进行不通过内核的通信；

- 区别：
  - 进程是系统资源分配的基本单位，因此线程只拥有一点再运行中必不可少的资源，如程序计数器、寄存器、栈等，其余的资源需要访问隶属进程的资源；

  - 线程是CPU调度的最小单位，因此同一个进程中的线程切换只需要保存和设置少量的寄存器内容，而不属于同一个进程的线程之间的切换，涉及到进程切换，需要当前执行进程CPU环境的保存及新调度进程CPU环境的设置，相对来说进程切换的开销远大于线程切换的开销；`线程有自己的寄存器和堆栈`

  - 通信方面，线程之间的通信可以通过同一进程中的共享数据通信，而进程之间的通信需要借助IPC；

  - 稳定性方面，多线程程序如果有一个线程对共享数据造成破坏或崩溃，会影响整个程序，导致崩溃，但是在多进程程序中，进程间是相互独立的，一个进程出错或崩溃不会导致整个程序崩溃，所以在稳定性和健壮性方面，多进程更好；`进程更安全，但是慢一点，线程快，性能好，但是不够安全`

#### 线程的实现方式？有什么区别？*

  C++ 静态局部变量 能保证线程安全 

  问了别的方式std::call_once或者静态成员变量，但是一般都会用静态局部变量 

  C++没有java的volatile能阻止指令重排，不能用DCL 

#### 进程通信方法

1. 管道pipe
   - 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。
   - 只支持半双工通信（单向交替传输）；
   - 只能在父子进程或者兄弟进程中使用。
2. 命名管道FIFO
   - 去除了管道只能在父子进程中使用的限制。
   - FIFO常用于客户-服务器（C/S）应用程序中，FIFO用作汇聚点，在客户进程和服务器进程之间传递数据。
3. 消息队列
   - 消息队列是按照FIFO来管理消息的；
   - 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
   - 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
   - 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。
4. 信号量
   - 信号量是一个整型变量sem，包含两个原子操作P( )、V( )，也就是对信号量的-1和+1操作；
   - 当一个线程访问临界区，信号量为正，则可以进行P操作，如果信号量等于0，则线程睡眠，等待信号量大于0；如果一个线程完成了对临界区的访问，会对信号量执行V操作，信号量+1，同时会唤醒睡眠的线程；
   - 信号量是被保护的变量，在初始化完成后，唯一改变一个信号量的值的办法就是通过P、V操作；
   - P操作能够产生阻塞，V操作不会阻塞；
   - 信号量允许同一时刻多个线程访问同一资源，最大线程数量不超过信号量的最大资源计数；
   - 如果信号量的最大资源计数为1，也就是只能取0和1，那么信号量就成了互斥量；
5. 共享内存
   - 也称为直接通信模式；
   - 每个进程都有私有地址空间，在每个地址空间内，明确的设置了`共享内存段(多个进程可以将同一个文件映射到它们的地址空间，也就是映射到共享内存段，从而实现共享内存)`；允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC，并且一个进程写，另一个进程立即可见，没有系统调用干预，没有数据的复制；
   - 该方法能够快速、方便的共享数据，但是必须同步数据访问，以免产生冲突（常利用`信号量`来实现同步）；
6. 套接字
   - 与其它通信机制不同的是，它可用于不同机器间的进程通信。

#### 进程同步方法

> 什么是同步：同步就是数据保持一致，无论是进程还是线程，都是实现了代码执行流程的分支，多个分支同时进行。多个分支互不干扰，但是又有些数据需要共享，让这些数据对所有分支保持一致即为同步。 
>
> 什么是通信：通信就是数据传输，数据存在两块不同的内存区域。通过某种方式互相传递。

- 进程的同步是目的，而进程间通信是实现进程同步的手段;

1. 信号量semaphore :信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。当它的值大于0时，表示当前可用资源的数量；当它的值小于0时，其绝对值表示等待使用该资源的进程个数。注意，信号量的值仅能由PV操作来改变。	

   - PV操作是典型的同步机制之一。用一个信号量与一个消息联系起来，当信号量的值为0时，表示期望的消息尚未产生；当信号量的值非0时，表示期望的消息已经存在。用PV操作实现进程同步时，调用P操作测试消息是否到达，调用V操作发送消息。

   -   使用PV操作实现进程同步时应该注意的是：

       （1）分析进程间的制约关系，确定信号量种类。在保持进程间有正确的同步关系情况下，哪个进程先执行，哪些进程后执行，彼此间通过什么资源（信号量）进行协调，从而明确要设置哪些信号量。
       （2）信号量的初值与相应资源的数量有关，也与P、V操作在程序代码中出现的位置有关。
       （3）同一信号量的P、V操作要成对出现，但它们分别在不同的进程代码中。

2. 管程:集中式同步进程，其基本思想是将共享变量和对它们的操作集中在一个模块中，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，易于保证正确性。

   - 从语言的角度看，管程主要有以下特性： 

     （1）模块化。管程是一个基本程序单位，可以单独编译; 

     （2）抽象数据类型。管程是中不仅有数据，而且有对数据的操作; 

     （3）信息掩蔽。管程外可以调用管程内部定义的一些函数，但函数的具体实现外部不可见; 

   - 为了保证共享变量的数据一致性，管程应互斥使用。 管程通常是用于管理资源的，因此管程中有`进程等待队列`和相应的`等待和唤醒操作`。在管程入口有一个等待队列，称为`入口等待队列`。当一个已进入管程的进程等待时，就释放管程的互斥使用权；当已进入管程的一个进程唤醒另一个进程时，两者必须有一个退出或停止使用管程。在管程内部，由于执行唤醒操作，可能存在多个等待进程（等待使用管程），称为`紧急等待队列`，它的优先级高于入口等待队列。

   - 因此，一个进程进入管程之前要先申请，一般由管程提供一个`enter`过程；离开时释放使用权，如果紧急等待队列不空，则唤醒第一个等待者，一般也由管程提供外部过程`leave`。

   - 管程内部有自己的等待机制。管程可以说明一种特殊的条件型变量：var c:condition；实际上是一个指针，指向一个等待该条件的PCB队列。对条件型变量可执行`wait`和`signal`操作：（联系P和V； take和give） 

   - `wait(c)`:若紧急等待队列不空，唤醒第一个等待者，否则释放管程使用权。执行本操作的进程进入C队列尾部； 

   - `signal(c)`:若C队列为空，继续原进程，否则唤醒队列第一个等待者，自己进入紧急等待队列尾部。 

#### 线程通信方法

线程里数据是共享的，即同一变量占用同一个内存地址，所以用全局变量就可以轻松实现数据交流。

#### 线程同步方法

> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。
>
> 从大的方面讲，线程的同步可分`用户模式的线程同步`和`内核对象的线程同步`两大类。
>
> - 用户模式中线程的同步方法主要有`原子访问`和`临界区`等方法。其特点是同步速度特别快，适合于对线程运行速度有严格要求的场合。
> - 内核对象的线程同步则主要由`事件`、`等待定时器`、`互斥量`、`信号量`等内核对象构成。由于这种同步机制使用了内核对象，使用时必须将线程从用户模式切换到内核模式，而这种转换一般要耗费近千个CPU周期，因此同步速度较慢，但在适用性上却要远优于用户模式的线程同步方式。

1. 互斥量Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资源，更有效率。

2. 信号量Semaphore：
   - 信号量是一个整型变量sem，包含两个原子操作P( )、V( )，也就是对信号量的-1和+1操作；
   - 当一个线程访问临界区，信号量为正，则可以进行P操作，如果信号量等于0，则线程睡眠，等待信号量大于0；如果一个线程完成了对临界区的访问，会对信号量执行V操作，信号量+1，同时会唤醒睡眠的线程；
   - 信号量是被保护的变量，在初始化完成后，唯一改变一个信号量的值的办法就是通过P、V操作；
   - P操作能够产生阻塞，V操作不会阻塞；
   - 信号量允许同一时刻多个线程访问同一资源，最大线程数量不超过信号量的最大资源计数；
   - 如果信号量的最大资源计数为1，也就是只能取0和1，那么信号量就成了互斥量；
   
3. 事件Event（信号）：
   - 允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后自动恢复为未激发状态。
   
   - 事件对象状态：有信号状态、无信号状态；
   
   - 事件对象类型：人工事件(手动设置)、自动事件(自动恢复)；
   
   - 自动事件对象，在被至少一个线程释放后自动返回到无信号状态；
   
   - 人工事件对象，获得信号后，释放可利用线程，但直到调用成员函数ReSet()才将其设置为无信号状态。在创建Cevent对象时，默认创建的是自动事件。
   
   - 使用”事件”机制应注意以下事项：
   
     （1）如果跨进程访问事件，必须对事件命名，在对事件命名的时候，要注意不要与系统命名空间中的其它全局命名对象冲突；
   
     （2）事件是否要自动恢复；
   
     （3）事件的初始状态设置。
   
     ```c++
     HANDLE CreateEvent(
     LPSECURITY_ATTRIBUTES lpEventAttributes,
     BOOL bManualReset,
     BOOL bInitialState,
     LPCSTR lpName
     );
     //bManualReset:TRUE，使用ResetEvent()手动重置为无信号状态；FALSE，当一个等待线程被释放时,自动重置状态为无信号状态。
     //bInitialState：指定事件对象的初始状态，当TRUE,初始状态为有信号状态；当FALSE,初始状态为无信号状态。
     
     #include "stdafx.h"
     #include<windows.h>
     #include<iostream>
     using namespace std;
     
     int number = 1;	//定义全局变量
     HANDLE hEvent;	//定义事件句柄
     
     unsigned long __stdcall ThreadProc1(void* lp) {
     	while (number < 100) {
     		WaitForSingleObject(hEvent, INFINITE);	//等待对象为有信号状态
     		cout << "thread 1 :"<<number << endl;
     		++number;
     		_sleep(100);
     		SetEvent(hEvent);
     	}
     	return 0;
     }
     
     unsigned long __stdcall ThreadProc2(void* lp) {
     	while (number < 100) {
     		WaitForSingleObject(hEvent, INFINITE);	//等待对象为有信号状态
     		cout << "thread 2 :"<<number << endl;
     		++number;
     		_sleep(100);
     		SetEvent(hEvent);
     	}
     	return 0;
     }
     int main() {
       	hEvent = CreateEvent(NULL, FALSE, TRUE, "event");
       	CreateThread(NULL, 0, ThreadProc1, NULL, 0, NULL);
       	CreateThread(NULL, 0, ThreadProc2, NULL, 0, NULL);
       	Sleep(10*1000);
       	system("pause");
           return 0;
       }
     ```
   
4. 临界区Critical Section：

   - 一段对临界资源访问的代码，称为临界区；临界区只允许`同时一个线程`对其访问，如果同时有其他线程试图访问临界区，会被挂起，直到临界区中的线程退出临界区；`临界区是指线程中的一段需要访问共享资源并且当另一个线程处于相应代码区域时便不会被执行的代码区域.`

   - 临界区在使用时以`CRITICAL_SECTION`结构对象保护共享资源，并分别用`EnterCriticalSection()`和`LeaveCriticalSection()`函数去标识和释放一个临界区。所用到的`CRITICAL_SECTION`结构对象必须经过`InitializeCriticalSection()`的初始化后才能使用，而且必须确保所有线程中的任何试图访问此共享资源的代码都处在此临界区的保护之下。否则临界区将不会起到应有的作用，共享资源依然有被破坏的可能

     ```c++
     #include "stdafx.h"
     #include<windows.h>
     #include<iostream>
     using namespace std;
     
     int number = 1;	//定义全局变量
     CRITICAL_SECTION Critical;		//定义临界区句柄
     
     unsigned long __stdcall ThreadProc1(void* lp) {
     	while (number < 100) {
     		EnterCriticalSection(&Critical);
     		cout << "thread 1 :"<<number << endl;
     		++number;
     		_sleep(100);
     		LeaveCriticalSection(&Critical);
     	}
     	return 0;
     }
     
     unsigned long __stdcall ThreadProc2(void* lp) {
     	while (number < 100) {
     		EnterCriticalSection(&Critical);
     		cout << "thread 2 :"<<number << endl;
     		++number;
     		_sleep(100);
     		LeaveCriticalSection(&Critical);
     	}
     	return 0;
     }
     
     int main() {
     	InitializeCriticalSection(&Critical);	//初始化临界区对象
     	CreateThread(NULL, 0, ThreadProc1, NULL, 0, NULL);
     	CreateThread(NULL, 0, ThreadProc2, NULL, 0, NULL);
     	Sleep(10*1000);
     	system("pause");
         return 0;
     }
     ```

5. 条件变量：

#### 生产者-消费者问题

1. 一个生产者、一个消费者、共用一个缓冲区；
2. 一个生产者、一个消费者、共用n个环形缓冲区；
3. 一组生产者，一组消费者，公用n个环形缓冲区；

#### 操作系统调度方法（进程调度方法）

1. 先来先服务FCFS
   - 如果进程在执行中阻塞，那么队列中的下一个会得到CPU；
   - 该调度方法非常的简单，但是平均等待时间波动较大，花费时间少的任务可能排在花费时间长的任务后面；
2. 最短作业优先SJF
   - 按照预测的完成时间来将任务入队；（非抢占）
   - 该调度算法拥有最优平均等待时间，但是可能导致饥饿，比如连续的短任务可能会使长任务饥饿，另外就是需要预知未来，需要预估下一个CPU突发的持续时间；
3. 最短剩余时间优先SRT
   - 按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；可能导致饥饿问题，对长进程不利。
4. 最高响应比优先HRRN
   - 在SJF的基础上，考虑到了饥饿现象（不可抢占、关注进程等待了多长时间、防止无限期推迟）；
   - R = (w + s) / s，选择R值最高的进程进入CPU，w是等待时间、s是执行时间；
   - 不可抢占、同样需要执行时间s，所以难以获得精确的时间，只能预估；
5. 时间片轮转
   - 将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；
   - 若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证，极限情况下退化为FCFS。
6. 优先级调度算法
   - 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
7. 多级反馈队列调度算法MFQ
   - 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

#### 基于优先级调度的方法存在什么问题

优先级调度可能会产生饥饿的问题，解决方法是偶尔提升一下优先级

#### 程序跟进程比较，是否一一对应

程序是静态的代码，进程是程序运行时产生的活动，启动一个程序的时候会产生一个或多个进程；

#### 进程线程地址空间



#### 虚拟内存VIRT、常驻内存RES、共享内存SHR？实际内存怎么计算？

VIRT：进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据，以及malloc、new分配的堆空间和分配的栈空间等；

RES：进程当前使用的内存大小，包括使用中的malloc、new分配的堆空间和分配的栈空间，但不包括swap out量；

SHR：除了自身进程的共享内存，也包括其他进程的共享内存；虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小；

- 虚拟内存是操作系统内核为了对进程地址空间进行管理（process address space management）而精心设计的一个逻辑意义上的内存空间概念。我们程序中的指针其实都是这个虚拟内存空间中的地址。因为这时候程序还没有运行，何谈物理内存空间地址？凡是程序运行过程中可能需要用到的指令或者数据都必须在虚拟内存空间中。虚拟内存与物理内存之间的映射机制就是页映射表，页映射表的基本原理是将程序运行过程中需要访问的一段虚拟内存空间通过页映射表映射到一段物理内存空间上，这样CPU访问对应虚拟内存地址的时候就可以通过这种查找页映射表的机制访问物理内存上的某个对应的地址。在程序运行过程中虚拟内存空间中需要被访问的部分会被映射到物理内存空间中。虚拟内存空间大只能表示程序运行过程中可访问的空间比较大，不代表物理内存空间占用也大。

- 驻留内存，顾名思义是指那些被映射到进程虚拟内存空间的物理内存。上图1中，在系统物理内存空间中被着色的部分都是驻留内存。比如，A1、A2、A3和A4是进程A的驻留内存；B1、B2和B3是进程B的驻留内存。进程的驻留内存就是进程实实在在占用的物理内存。一般我们所讲的进程占用了多少内存，其实就是说的占用了多少驻留内存而不是多少虚拟内存。因为虚拟内存大并不意味着占用的物理内存大。

- SHR是share（共享）的缩写，它表示的是进程占用的共享内存大小。程序中的一些动态库在内存中仅仅会保存/映射一份，如果某个进程运行时需要这个动态库，那么动态加载器会将这块内存映射到对应进程的虚拟内存空间中。多个进程之间通过共享内存的方式相互通信也会出现这样的情况。这么一来，就会出现不同进程的虚拟内存空间会映射到相同的物理内存空间。这部分物理内存空间其实是被多个进程所共享的，所以我们将他们称为共享内存，用SHR来表示。

- 一个进程的实际内存也就是进程的独占内存，计算方式为：驻留内存RES-共享内存SHR；

#### 既然多优先级队列+时间片轮转调度这么好，为什么还会出现死机情况?



#### 系统调用的过程

由于系统的有限资源可能被多个不同的应用程序访问，因此，如果不加以保护，那么用程序难免产生冲突。所以，现代操作系统都将可能产生冲突的系统资源给保护起来，阻止应用程序直接访问。这些系统资源包括文件、网络、IO、各种设备等。为了让应用程序有能力访问系统资源，也为了让应用程序能够借助操作系统做一些必须由操作系统支持的行为。每个操作系统都会提供一套接口，以供应用程序使用。这些接口往往通过中断来实现。

由于中断号是有限的，操作系统不舍得每一个系统调用对应一个中断号，而更倾向于用一个或少数几个中断号来对应所有的系统调用。Linux则使用int 0x80来触发所有系统调用。每个系统调用对应一份**系统调用号**，这个系统调用号在执行**int 0x80**指令前会放置在某个固定的寄存器里（eax)，对应的中断代码会取得这个系统调用号，并且调用正确的函数。

![img](https://img-blog.csdnimg.cn/20200709211508661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2ODIyMjE3,size_16,color_FFFFFF,t_70)

用户运行库函数（系统调用的封装），函数里面其实是执行的int 0x80指令。系统调用先把系统调用号保存在eax寄存器中，然后执行int0x80指令。int 0x80指令先进行切换堆栈（找到进程的堆栈，将寄存器值压入到内核栈中，将esp，ss设置成对应内核栈的值），查找相应中断向量的中断处理程序(system_call)并调用，随后system_call 从系统调用表中找到相应的系统调用进行调用，调用结束后从system_call中返回。

![img](https://img-blog.csdnimg.cn/20200712204654806.png)

#### 产生死锁的原因 

1. 竞争不可剥夺的资源
2. 进程间的调度顺序存在问题

- 产生死锁的四个必要条件：
  - 互斥：在一个时间只能有一个进程使用资源；
  - 持有并等待：进程保持至少一个资源正在等待获取其它进程持有的额外资源；
  - 无抢占：一个资源只能被进程自愿释放，不能被抢占；
  - 循环等待：多个进程组成了一条环路，循环等待下一个进程所持有的资源；`死锁必有环，有环不一定死锁`

#### 处理死锁的方法

- **鸵鸟策略**：忽略死锁问题；

- **死锁避免** `确保系统永远不进入不安全状态`

  ​	**安全状态**：

  - 需要系统具有一些额外的先验信息提供，最简单和最有效的模式是要求每个进程声明它可能需要的每个类型资源的最大数目；
  - 资源的分配状态是通过限定`提供与分配的资源数量`和`进程的最大需求`；
  - 死锁避免算法动态检查资源分配状态，以确保永远不会有一个环形等待状态（不安全状态）；
  - 当一个进程请求可用资源，系统必须判断立即分配 是否能使系统处于安全状态；

- **死锁预防**  `至少破坏一个产生死锁的条件`

  - 互斥：
  - 持有并等待：需要进程请求并分配其所有资源，它开始执行之前或允许进程请求资源 仅当 进程没有资源时；`资源利用率低，可能导致饥饿`
  - 无抢占：如果进程占有某些资源，同时请求其它不能被立即分配的资源，那么就释放当前正占有的资源，将被抢占资源添加到资源列表中，只有当它能够获得旧的资源以及它请求的新的资源，进程才能得到执行；
  - 循环等待：对所有资源类型进行排序，并要求每个进程按照资源顺序进行申请；

- **死锁检测恢复**

  - 死锁检测算法

  - 利用抢占恢复
  - 利用回滚恢复
  - 通过杀死进程恢复

## 3. Linux

#### 常用的linux指令讲一下

- 求助 --help  man  info  doc

- 关机  who  sync  shutdown

- Vim模式：

  - 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容；

    编辑模式（Insert mode）：按下 "i" 等按键之后进入，可以对文本进行编辑；

    指令列模式（Bottom-line mode）：按下`:`按键之后进入，用于保存退出等操作。

    | 命令 | 作用                                                         |
    | ---- | ------------------------------------------------------------ |
    | :w   | 写入磁盘                                                     |
    | :w!  | 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 |
    | :q   | 离开                                                         |
    | :q!  | 强制离开不保存                                               |
    | :wq  | 写入磁盘后离开                                               |
    | :wq! | 强制写入磁盘后离开                                           |

- 文件管理

  - ### 1. ls

    列出文件或者目录的信息，目录的信息就是其中包含的文件。

    ```
    # ls [-aAdfFhilnrRSt] file|dir
    -a ：列出全部的文件
    -d ：仅列出目录本身
    -l ：以长数据串行列出，包含文件的属性与权限等等数据
    ```

    ### 2. cd

    更换当前目录。

    ```
    cd [相对路径或绝对路径]
    ```

    ### 3. mkdir

    创建目录。

    ```
    # mkdir [-mp] 目录名称
    -m ：配置目录权限
    -p ：递归创建目录
    ```

    ### 4. rmdir

    删除目录，目录必须为空。

    ```
    rmdir [-p] 目录名称
    -p ：递归删除目录
    ```

    ### 5. touch

    更新文件时间或者建立新文件。

    ```
    # touch [-acdmt] filename
    -a ： 更新 atime
    -c ： 更新 ctime，若该文件不存在则不建立新文件
    -m ： 更新 mtime
    -d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date="日期或时间"
    -t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm]
    ```

    ### 6. cp

    复制文件。如果源文件有两个以上，则目的文件一定要是目录才行。

    ```
    cp [-adfilprsu] source destination
    -a ：相当于 -dr --preserve=all
    -d ：若来源文件为链接文件，则复制链接文件属性而非文件本身
    -i ：若目标文件已经存在时，在覆盖前会先询问
    -p ：连同文件的属性一起复制过去
    -r ：递归复制
    -u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制
    --preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了
    ```

    ### 7. rm

    删除文件。

    ```
    # rm [-fir] 文件或目录
    -r ：递归删除
    ```

    ### 8. mv

    移动文件。

    ```
    # mv [-fiu] source destination
    # mv [options] source1 source2 source3 .... directory
    -f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖
    ```

- 权限管理

  - ```
    # chmod [ugoa]  [+-=] [rwx] dirname/filename
    - u：拥有者
    - g：所属群组
    - o：其他人
    - a：所有人
    - +：添加权限
    - -：移除权限
    - =：设定权限
    ```

  - 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。

  - 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。

  - ```
    # ln [-sf] source_filename dist_filename
    -s ：默认是实体链接，加 -s 为符号链接
    -f ：如果目标文件存在时，先删除目标文件
    ```

  - 实体链接：

    在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。

    删除任意一个条目，文件还是存在，只要引用数量不为 0。

    有以下限制：不能跨越文件系统、不能对目录进行链接。

  - 符号链接：

    符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。

    当源文件被删除了，链接文件就打不开了。

    因为记录的是路径，所以可以为目录建立符号链接。

- 获取文件内容

  - ### 1. cat

    取得文件内容。

    ```
    # cat [-AbEnTv] filename
    -n ：打印出行号，连同空白行也会有行号，-b 不会
    ```

    ### 2. tac

    是 cat 的反向操作，从最后一行开始打印。

    ### 3. more

    和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。

    ### 4. less

    和 more 类似，但是多了一个向前翻页的功能。

    ### 5. head

    取得文件前几行。

    ```
    # head [-n number] filename
    -n ：后面接数字，代表显示几行的意思
    ```

    ### 6. tail

    是 head 的反向操作，只是取得是后几行。

    ### 7. od

    以字符或者十六进制的形式显示二进制文件。

- 指令与文件搜索

  - ### 1. which

    指令搜索。

    ```
    # which [-a] command
    -a ：将所有指令列出，而不是只列第一个
    ```

    ### 2. whereis

    文件搜索。速度比较快，因为它只搜索几个特定的目录。

    ```
    # whereis [-bmsu] dirname/filename
    ```

    ### 3. locate

    文件搜索。可以用关键字或者正则表达式进行搜索。

    locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。

    ```
    # locate [-ir] keyword
    -r：正则表达式
    ```

    ### 4. find

    文件搜索。可以使用文件的属性和权限进行搜索。

    ```
    # find [basedir] [option]
    example: find . -name "shadow*"
    ```

- 进程管理：

  - ### 1. ps

    查看某个时间点的进程信息。

    示例：查看自己的进程

    ```
    # ps -l
    ```

    示例：查看系统所有进程

    ```
    # ps aux
    ```

    示例：查看特定的进程

    ```
    # ps aux | grep threadx
    ```

    ### 2. pstree

    查看进程树。

    示例：查看所有进程树

    ```
    # pstree -A
    ```

    ### 3. top

    实时显示进程信息。

    示例：两秒钟刷新一次

    ```
    # top -d 2
    ```

    ### 4. netstat

    查看占用端口的进程

    示例：查看特定端口的进程

    ```
    # netstat -anp | grep port
    ```

- 系统管理：

  - top：动态显示进程信息和系统运行统计信息

    free：显示系统运行的统计信息：内存 缓存 缓冲 交换分区；

    ipcs -s/-q/-m：分别显示系统的信号量 消息队列 共享内存

    ipcrm -s/-q/-m id ：根据id 删除信号量 消息队列 共享内存

    lsof：（list open file）：显示系统当前打开的所有文件描述符，所有所有。。。所有

    mpstat：实时监控多处理器系统上每个处理器的使用情况

    vmstat：实时输出系统各个资源的使用情况

- 网络通讯命令:

  - ping：测试网络连通性；

    ifconfig/ip：显示或设置网络设备；

    netstat/ss：显示网络相关信息；

    service：管理系统运行的服务器；

    mail：查看、发送电子邮件；

    write：给用户发信息；

    tcpdump：抓包工具

    nc：快速构建网络连接；

    strace：跟踪程序运行过程中执行的系统调用和接受到的信号，并将系统调用名，参数，返回值以及信号名输出到 标准输出 或者 指定的文件中

    netstat：打印本地网卡接口上的全部连接、路由表信息、网卡接口信息。常用：显示tcp连接以及状态。

- 打包压缩

  - ### 1. gzip

    gzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。

    经过 gzip 压缩过，源文件就不存在了。

    有 9 个不同的压缩等级可以使用。

    可以使用 zcat、zmore、zless 来读取压缩文件的内容。

    ```
    $ gzip [-cdtv#] filename
    -c ：将压缩的数据输出到屏幕上
    -d ：解压缩
    -t ：检验压缩文件是否出错
    -v ：显示压缩比等信息
    -# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6
    ```

    ### 2. bzip2

    提供比 gzip 更高的压缩比。

    查看命令：bzcat、bzmore、bzless、bzgrep。

    ```
    $ bzip2 [-cdkzv#] filename
    -k ：保留源文件
    ```

    压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gzip、bzip2、xz 将打包文件进行压缩。

    ```
    $ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename...  ==打包压缩
    $ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件]              ==查看
    $ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录]    ==解压缩
    -z ：使用 zip；
    -j ：使用 bzip2；
    -J ：使用 xz；
    -c ：新建打包文件；
    -t ：查看打包文件里面有哪些文件；
    -x ：解打包或解压缩的功能；
    -v ：在压缩/解压缩的过程中，显示正在处理的文件名；
    -f : filename：要处理的文件；
    -C 目录 ： 在特定目录解压缩。
    ```

## 4. 设计模式

### 单例模式

#### 懒汉式

懒加载：实例对象是第一次被调用的时候才真正的构建，而不是程序启动它就构建好了等着来调用，这种滞后构建的方式就叫做懒加载；懒加载的好处在于，有的对象的构建开销是比较大的，假如这个对象在项目启动时就构建，万一从来就没有调用过，那么就比较浪费了，只有真正需要使用了再去构建，这是更加合理的；

```c++
class singleton{
private: 
    singleton(){}
private:
    static singleton *instence;

public:
    static singleton *getinstence();
};
.cpp
singleton* singleton::instence = 0;
singleton::singleton(){
    std::cout<<"singleton creat success !"<<endl;
}
singleton* singleton::getinstence(){

    if(instence == NULL){
        instence = new singleton();
    }
    return instence;
}
```

线程安全问题：在构建对象的时候要同步，而在使用对象的时候不需要同步；

```c++
class singleton{
private:
    singleton();
private:
    static singleton *instence;
public:
    static singleton *getinstence();
};
.cpp
singleton::singleton(){
    cout<<"creat singleton success !" << endl;
}
singleton* singleton::instence = 0;
singleton* singleton::getinstence(){
    if(instence == NULL){
        lock();
        if(instence == NULL)
            instence = new singleton();
        unlock();
    }
    return instence;
}
```

懒汉双锁式，也存在一定的线程不安全问题，主要原因就在于一个指令重排的问题，首先在`instence = new singleton();`这一句中，new的顺序是先申请变量内存，然后初始化，最后将变量给到instence，但是因为指令重排的原因，可能是先执行3再执行2，这就导致thread1再new的3过程时，thread2进入getinstence（），这时候会出现if判断instence已经存在，就直接返回了instence，而这个instence是未初始化的instence，导致线程的不安全；解决方式是将new这个过程原子化；

## 5. 数据库



#### Redis的5大结构



#### Redis 的 zset 的底层数据结构



#### Redis 实现分布式锁



#### 数据库索引



#### B与B+的区别，B+树高度低带来的好处是啥



## 6. C11

#### 左值右值的区别



#### 智能指针

智能指针类将一个计数器与类指向的对象相关联，引用计数跟踪该类有多少个对象共享同一指针。每次创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数；对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。智能指针就是模拟指针动作的类。所有的智能指针都会重载 -> 和 * 操作符。智能指针还有许多其他功能，比较有用的是自动销毁。这主要是利用栈对象的有限作用域以及临时对象（有限作用域实现）析构函数释放内存。

- 智能指针的设计思想
- 为什么摒弃auto_ptr
- unique_ptr为什么优于auto_ptr
- 如何选择只能指针



#### 完美转发



#### C++ 4种cast 区别和主要使用场景



## 7. 网络编程

#### select \ poll \ epoll 的区别？

这三个都是IO复用的具体实现，其中select出现的最早，然后是poll，最后是epoll；

select：允许应用程序来监视一组文件描述符，等待一个或者多个文件描述符成为就绪状态，从而完成IO操作；

poll：poll的功能与select是类似的，也是等待一组文件描述符中的一个成为就绪状态；

epoll：epoll是Linux内核为处理大量句柄而改进的poll，是linux特有的I/O函数；epoll有两种工作方式，LT水平触发 、ET边沿触发。LT是select/poll的工作方式，比较低效，而ET是epoll具有的高速工作方式。

select与poll的区别：

- select 会修改描述符，而 poll 不会；
- select 的描述符类型使用数组实现，`FD_SETSIZE`大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 `FD_SETSIZE`之后重新编译；而 poll 没有描述符数量的限制；
- poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
- 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。
- select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。
- 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。

epoll对select与poll的区别：

- epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。
- epoll 仅适用于 Linux OS。
- epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。
- epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。

应用场景：

- select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景；
- poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
- 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接，可以用epoll；

不用epoll的地方：

- 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。
- 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。

#### epoll模型的工作原理



#### IO多路复用与多进程

如果压力不是很大，并且处理性能相对于IO可以忽略不计

- IO多路复用+单进（线）程比较省资源
- 适合处理大量的闲置的IO
- IO多路复用+多单进（线）程与线程池方案相比有好处，但是并不会有太大的优势

如果压力很大，什么方案都得跪，这时就得扩容。当然因为IO多路复用+单进（线）程比较省资源，所以扩容时能省钱。

#### 多进程和多线程



#### IO模型

有五种IO模型：阻塞IO、非阻塞IO、异步IO、IO复用、信号驱动IO；

阻塞IO：

非阻塞IO：

信号驱动IO：

异步IO：

#### 线程池？线程池用过没，需要注意哪些事项

> 这里主要是考察大家对于各种连接池的理解。提前创建一定数量的连接，需要的时候直接使用即可，不用每次频繁的创建连接。常用的连接池有redis连接池，HTTP连接池等。这里会涉及到最大的连接数和最小的连接数。那么连接数的大小一般怎么控制？

- 当前连接数小于最小连接数，那么就创建连接
- 如果连接池有空闲则复用
- 如果此时当前连接数大于最大连接数，考虑设置超市等待，异常处理

#### socket的流程

先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。

![img](https://upload-images.jianshu.io/upload_images/14479440-913393a6f4c24564.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/478/format/webp)

- 这个connect（）与accept（）的过程其实就是TCP三次握手的过程；

```c++
//socket建立TCP连接-服务器端
/*
1.socket()创建TCP套接字                                                                              
2.bind()将创建的套接字绑定到一个本地地址和端口上                                        
3.listen()，将套接字设为监听模式，准备接受客户请求                                        
4.accept()等用户请求到来时接受，返回一个对应此连接新套接字   
5.用accept()返回的套接字和客户端进行通信，recv()/send() 接受/发送信息。                               
6.返回，等待另一个客户请求。
7.关闭套接字
*/
//socket建立TCP连接-客户端
/*
1.socket()创建TCP套接字。
2.connect()建立到达服务器的连接。
3.与客户端进行通信，recv()/send()接受/发送信息，write()/read() 子进程写入管道，父进程从管道中读取信息然后send给客户端。
4. close() 关闭客户连接。
*/ 
```

#### 如果socket出现问题，你如何定位到这个错误呢？

一般用侦听软件可以捕获错误，例如: Fiddler

#### Socket是什么？Socket属于网络的哪一层？

socket是应用层与传输层的一个抽象，将复杂的TCP/IP协议隐藏在Socket接口之后，只对应用层暴露简单的接口，以实现进程在网络中通信；

socket是一种特殊的文件，它也有文件描述符，进程可以打开一个socket，并且像处理文件一样对它进行read()和write()操作，而不必关心数据是怎么在网络上传输的

socket是一个tcp连接的两端

#### Socket如何唯一标识一个进程？

socket基于tcp协议实现，网络层的**ip地址**唯一标识一台主机，而**传输层的协议+端口号**可以唯一标识绑定到这个端口的进程；

#### 通信双方如何进行端口绑定？

通常服务端启动时会绑定一个端口提供服务，而客户端在发起连接请求时会被随机分配一个端口号

#### Socket是全双工的吗？

基于TCP协议，是全双工的

#### HTTP协议是全双工的吗？

HTTP 协议设计的初衷本身就是请求/响应模式，这是规范决定的，也就是单工模式通信，但是在技术上是可以利用下层的 TCP 来进行全双工通信的。

## 8. C++

#### malloc和new

- malloc与free成对使用，new与delete成对使用，malloc是函数，而new是操作符重载；
- 调用构造函数：new分为两步，先分配内存，然后调用对象的构造函数，而malloc仅仅是分配内存，不会调用构造函数；
- 返回值不同：new返回值为对象数据类型的指针，而malloc返回值为void指针；

#### 构造函数和析构函数能不能是虚函数

构造函数不可以是虚函数：虚函数的调用是需要虚函数表指针的，指针指向对应虚函数的地址，而指针是存放在对象的内存空间中的，如果构造函数声明为虚函数，那么因为对象还没有创建，没有对象的内存空间，也就没办法用虚函数表来调用虚构造函数了；

析构函数可以是虚函数：在使用基类指针或引用调用子类的时候，最好将基类的析构函数定义为虚析构函数，否则可能导致内存泄漏的问题；主要是在父类指针指向子类对象的时候，如果释放了父类指针，这时只会调用父类的析构函数，释放掉了子类中的父类部分，而派生类部分是没有被析构掉的，造成内存泄漏；

*这份信息通常是由一个所谓 vptr（virtual table pointer —— 虚函数表指针）指针指出。vptr 指向一个由函数指针构成的数组，称为 vtbl（virtual table —— 虚函数表）；每一个带有 virtual 函数的类都有一个相应的 vtbl。当对象调用某一 virtual 函数，实际被调用的函数取决于该对象的 vptr 所指向的那个 vtbl，接着编译器在其中寻找适当的函数指针，从而调用对应类的函数。*

#### 模板与继承的对比，模板的缺点，模板是如何编译的*

模板默认内联，且没有虚表指针，调用开销小 ；

编译慢、编译产物更占用内存 ；

编译期碰到了就生成需要的代码，每个.o都会有用到的定义，所以链接的时候要去掉重定义，因此编的慢；

#### 智能指针-STL四种（细、手写智能指针）

智能指针：智能指针其实就是一个类，指针对象离开作用域之后会自动调用析构函数，释放内存，防止出现内存泄漏的问题；

**auto_ptr** 

c11建议弃用，主要原因就是auto指针是唯一拥有者模型，也就是在通过拷贝构造函数或者赋值运算符进行操作之后，资源的唯一拥有者将变为新的指针对象，而原来的指针对象变为了null，所以如果不小心再次使用了原指针，则必然会导致程序的崩溃；

**unique_ptr**

unique指针也是唯一拥有者模型，它相比于auto指针，直接禁止了通过拷贝构造或者赋值操作符的copy行为，但是可以通过move函数实现资源所有权的转移，就是从一个unique指针转移到另一个unique指针，旧的unique指针不在拥有资源的所有权；

```c++
//构造 unique_ptr
std::unique_ptr<Entity> e1(new Entity);     //ok
std::unique_ptr<Entity> e1 = std::make_unique<Entity>();   // preferred
auto e1 = std::make_unique<Entity>();   //preferred
//移动 unique_ptr
std::unique_ptr<Entity> e2 = std::move(e1);
func(move(e1));
```

**shared_ptr**

shared指针是共享的拥有者模型，加入了引用计数机制；

**weekly_ptr**



#### 浅拷贝与深拷贝



#### 一个类A，里面有两个整型变量，一个成员函数，两个虚函数，问这个类占多大内存



#### 空悬指针与野指针？怎么避免空悬指针？



#### NULL与nullptr差别



#### 虚函数以及虚函数表指针、虚函数表原理



#### .cpp与.c编译时的区别



#### 数组和链表的区别



#### 重载与重写



#### C++ 的内存管理是怎么实现的



#### 指针和引用



#### strlen和sizeof



#### static关键字



#### 时间复杂度，如果一个算法的时间复杂度是O(1)代表的含义是什么



#### 头文件重复的包含和重复的引用



#### struct与union有什么区别？ 



#### struct内存对齐原则有哪些？

为什么要内存对齐：比如在一个32为操作系统中，数据总线是32位的，意味着读取一次就可以读出4个字节，那如果没有内存对齐，可能一个4字节的数据变量需要用两次IO操作才能够读取出来，而IO操作是非常耗时的，所以利用内存对齐原则可以减少IO操作的次数，减少系统的开销；

1、没有#pragma pack宏的对齐规则

- 1.结构体的起始存储位置必须是能够被该结构体中最大的数据类型所整除。
- 2.每个数据成员存储的起始位置是自身大小的整数倍(比如int在32位机为4字节，则int型成员要从4的整数倍地址开始存储)。
- 3.结构体总大小（也就是sizeof的结果），必须是该结构体成员中最大的对齐模数的整数倍。若不满足，会根据需要自动填充空缺的字节。
- 4.结构体包含另一个结构体成员，则被包含的结构体成员要从其原始结构体内部最大对齐模数的整数倍地址开始存储。(比如struct a里存有struct b，b里有char,int,double等元素,那b应该从8的整数倍开始存储。)
- 5.结构体包含数组成员，比如char a[3],它的对齐方式和分别写3个char是一样的，也就是说它还是按一个字节对齐。如果写：typedef char Array[3],Array这种类型的对齐方式还是按一个字节对齐，而不是按它的长度3对齐。
- 6.结构体包含共用体成员，则该共用体成员要从其原始共用体内部最大对齐模数的整数倍地址开始存储。

2、存在#pragma pack宏的对齐

```
#pragma pack (n)    //编译器将按照n个字节对齐  
#pragma pack ()     //取消自定义字节对齐方式
```

那么对齐规则就变成下面的

- 结构，联合，或者类的数据成员，第一个放在偏移为0的地方，以后每个数据成员的对齐，按照#pragma pack指定的数值和自身对齐模数中较小的那个。

#### inline关键字有什么作用？ 



#### 内联函数与宏定义的区别？ 



#### 什么是内存泄漏？如何避免？

<u>为什么会存在内存泄漏问题？</u>

通常来说，一个线程的栈内存是有限的，通常来说是 8M 左右（取决于运行的环境）。栈上的内存通常是由编译器来自动管理的。当在栈上分配一个新的变量时，或进入一个函数时，栈的指针会下移，相当于在栈上分配了一块内存。我们把一个变量分配在栈上，也就是利用了栈上的内存空间。当这个变量的生命周期结束时，栈的指针会上移，相同于回收了内存。

由于栈上的内存的分配和回收都是由编译器控制的，所以在栈上是不会发生内存泄露的，只会发生栈溢出（Stack Overflow），也就是分配的空间超过了规定的栈大小。

而堆上的内存是由程序直接控制的，程序可以通过 malloc/free 或 new/delete 来分配和回收内存，如果程序中通过 malloc/new 分配了一块内存，但忘记使用 free/delete 来回收内存，就发生了内存泄露。

<u>避免方法：</u>

- 尽量使用智能指针，而不是手动地去管理内存
- 使用 std::string 来替代 char*。使用 std::string 无需关心内存管理，它已经很好地在内部实现了内存管理。
- 无论如何都不要使用一个裸指针，除非逼不得已（比如要用它来指向一个旧的库）
- 在 C++ 中最好的避免内存泄漏的方式是尽量少的使用 new 和 delete 函数，最好是0使用。当你确实需要动态内存的时候，构造一个 RAII 类来在析构的时候自动地 delete 所有动态申请的内存。 RAII 类在构造函数中申请内存，而在析构函数释放内存，所以这可以保证在 RAII 对象离开作用域的时候，自动地释放内存。
- 在你每次确实需要申请动态内存的时候，先写 new 和 delete 语句。然后再在中间添加你的功能模块！这样做确保你不会忘记释放内存！

#### strcpy和memcpy的区别？



#### 为什么引入抽象基类和纯虚函数？



#### 为什么传指针比传引用安全？



#### 虚函数和纯虚函数有什么区别



#### 构造函数与析构函数的调用顺序是怎样的



#### 多态与底层

多态是c++面向对象的三大特性之一，

虚函数：在类的成员函数前加上virtual关键字，就构成了虚函数；

多态的底层是利用虚函数表来实现的；虚函数表是通过一块连续内存来存储虚函数的地址，这张表解决了继承，虚函数（重写）的问题，在有虚函数的对象实例中都存在一张虚函数表，虚函数表就像一张地图，指明了实际应该调用的虚函数。虚表中依次存储了各个虚函数的地址，且存放的顺序和代码中定义的虚函数的顺序一致。当进行多态调用时，编译器根据传入对象的类别，找到对应的vfptr（虚表指针），再查看你要调用的函数在类中定义的位置，来找到该虚函数在虚表中存储的位置，实现调用。

#### c++中map底层实现，红黑树说一下

红黑树形式的存储的键值是有序的，同时红黑树的插入，删除可以在O(logn)的完成。

红黑树的性质

- 红黑树的每个节点要么是红色要么是黑色
- 红黑树的根节点一定是黑色
- 红黑树的所有外部节点都是黑色
- 红黑树的所有有红色节点的两个子节点一定是黑色节点
- 红黑树从根到任意一个外部节点的路径上的黑色节点的数目相同

说到map，也说说hashmap和Treemap。

C++中unordered_map的底层是用哈希表来实现的，通过key的哈希路由到每一个桶（即数组）用来存放内容。通过key来获取value的时间复杂度就是O（1）。因为key的哈希容易碰撞，所以需要对碰撞做处理。unordered_map里的每一个数组（桶）里面存的其实是一个链表，key的哈希冲突以后会加到链表的尾部，这是再通过key获取value的时间复杂度就变成O(n），当碰撞很多的时候查询就会变慢。为了优化这个时间复杂度，map的底层就把这个链表转换成了红黑树，这样虽然插入增加了复杂度，但提高了频繁哈希碰撞时的查询效率，使查询效率变成O(log n)。

#### HashMap的底层实现；HashMap是否是线程安全的



#### 排序算法，推时间复杂度；



#### STL库与底层的实现；





#### define和const的区别？



#### 仿函数与指针函数有啥区别？



#### unordered_map 和map区别

#### 5.递归层数太多会怎么样，为什么



## 9. 其他

#### 软件工程常用开发模型？ 软件开发流程 



#### Utf-8几个字节，汉字呢？



#### Memory load



#### move，forward



#### 动态链接库原理？静态链接库跟动态链接库异同比较？动态链接库实际存了哪些东西? 怎么引用动态链接库，什么是动态库、静态库？



#### gdb常用命令有什么



#### 哈希冲突有哪些解决方法



#### LRU如何实现的



## 10 手撕算法

### 链表

#### 建立一个双向链表；

```c++
//
```

#### 设计一个数据结构 list:  rpush rpop lpush lpop index 五种方法的时间复杂度均为 O(1)



#### 反转链表

```c++
//递归法
struct ListNode{
    int val;
    ListNode *next;
    ListNode(int x) : val(x),next(NULL) {}
};
class solution{
public:
    ListNode * reverseList(ListNode *head){
        if(head == NULL || head->next == NULL) return head;
        ListNode * last = reverseList(head->next);
        head->next->next = head;
        head->next = NULL;
        return last;        
    }
};
//迭代法
class solution{
public:
    ListNode * reverseList(ListNode *head){
        if(head == NULL) return NULL;
        ListNode * pre = NULL;
        ListNode * cur = head;
        while(cur != NULL){
            ListNode * temp = cur->next;
            cur->next = pre;
            pre = cur;
            cur = temp;
        }
        return pre;
    }
}
```

#### leetcode 92 反转链表从m到n

```c++
//迭代法
struct ListNode{
    int val;
    ListNode * next;
    ListNode(int x) : val(x),next(NULL) {}
}
class solution{
public:
    ListNode * reverse(ListNode *head, int m, int n){
        if(m == 1){
            ListNode *ptr = reverseN(head,n);
            return ptr;
        }
        ListNode *last = reverse(head->next,m-1,n-1);
        head->next = last;
        return head;
    }
    ListNode * reverseN(ListNode *head, int n){
        if(n == 1){
            successed = head->next;
            return head;
        }
        ListNode *last = reverseN(head->next,n-1);
        head->next->next = head;
        head->next = successed;
        return last;
    }
    ListNode *successed;
};
```

#### leetcode 25 K个一组反转链表；



#### 判断链表是否有环,并返回入环节点

```c++
//
/**
 * Definition for singly-linked list.
 * struct ListNode {
 *     int val;
 *     ListNode *next;
 *     ListNode(int x) : val(x), next(NULL) {}
 * };
 */
class Solution {
public:
    ListNode *detectCycle(ListNode *head) {
        if(head == NULL) return NULL;
        if(head->next == head) return head;
        ListNode* first = head;
        ListNode* second = head;
        while(second != NULL && second->next != NULL){
            first = first->next;
            second = second->next->next;
            if(first == second){
                first = head;
                while(first != second){
                    first = first->next;
                    second = second->next;
                }
                return first;
            }
        }
        return NULL;
    }
};
```

#### 判断两个链表是否相交

```c++
//
```

#### 单链表只遍历一次，要找到链表的中间位置要怎么做；



#### 找到两个链表的首个公共节点；

```c++
//ok
/**
 * Definition for singly-linked list.
 * struct ListNode {
 *     int val;
 *     ListNode *next;
 *     ListNode(int x) : val(x), next(NULL) {}
 * };
 */
class Solution {
public:
    ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) {
        if(headA == NULL || headB == NULL) return NULL;
        ListNode* first = headA;
        ListNode* second = headB;
        while(first != second){
            first = first == NULL ? headB : first->next;
            second = second == NULL ? headA : second->next;
        }
        return first;
    }
};
```

二叉树的Z型遍历；

```c++
//
```

#### 二叉树的层序遍历

```c++
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {//BFS
public:
    vector<vector<int>> levelOrder(TreeNode* root) {
        if(root == NULL) return {};
        queue<TreeNode*> deq;
        deq.push(root);
        vector<vector<int>> res;
        while(!deq.empty()){
            int size = deq.size();
            vector<int> vec;
            while(size--){
                root = deq.front();
                deq.pop();
                vec.push_back(root->val);
                if(root->left != NULL) deq.push(root->left);
                if(root->right != NULL) deq.push(root->right);
            }
            res.push_back(vec);
        }    
        return res;            
    }
};
//自底向上的层序遍历
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    vector<vector<int>> levelOrderBottom(TreeNode* root) {
        if(root == NULL) return {};
        int n = getDepth(root);
        vector<vector<int>> res(n,vector<int>());
        queue<TreeNode*> queue;
        queue.push(root);
        while(!queue.empty()){
            int size = queue.size();
            vector<int> level;
            while(size--){
                root = queue.front();
                queue.pop();
                level.push_back(root->val);
                if(root->left != NULL) queue.push(root->left);
                if(root->right != NULL) queue.push(root->right);
            }
            res[--n] = level;
        }
        return res;
    }
    int getDepth(TreeNode * root){
        if(root == NULL) return 0;
        return max(getDepth(root->left),getDepth(root->right))+1;
    }
};

//Z型遍历
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {//BFS+deque  法二：层序遍历，奇数reverse偶数不反转；
public:
    vector<vector<int>> zigzagLevelOrder(TreeNode* root) {
        if(root == NULL) return {};
        vector<vector<int>> res;
        deque<TreeNode*> deque;
        deque.push_back(root);
        bool sw = true;
        while(!deque.empty()){
            int size = deque.size();
            vector<int> level;
            while(size--)
                if(sw == true){
                    root = deque.front();
                    deque.pop_front();
                    level.push_back(root->val);
                    if(root->left != NULL) deque.push_back(root->left);
                    if(root->right != NULL) deque.push_back(root->right);
                }
                else{
                    root = deque.back();
                    deque.pop_back();
                    level.push_back(root->val);
                    if(root->right != NULL) deque.push_front(root->right);
                    if(root->left != NULL) deque.push_front(root->left);
                }
            res.push_back(level);
            sw = !sw;
        }
        return res;        
    }
};
```



LFU leetcode 460

场景类算法题有依赖关系的进程启动管理

二分法求浮点数平方根，不得递归，精度要求0.001 

多线程打印ABCD

```c++
#
```

#### 实现两个线程交替打印AB

```c++
#include<iostream>
#include<windows.h>
#include<string>

using namespace std;

class THREAD_DATA{
public:
    int maxnum;
    string data;
    THREAD_DATA() : maxnum(0) ,data("") {}
    THREAD_DATA(int num,string str) : maxnum(num),data(str) {}
};

HANDLE cout_Mutex;
HANDLE hEvent;

DWORD WINAPI MyThread1(LPVOID lpParamter){

    THREAD_DATA *data = (THREAD_DATA *)lpParamter;
    for(int i = 0;i < data->maxnum;++i){
        WaitForSingleObject(hEvent,INFINITE);
        cout<<data->data<<"A"<<endl;
        //ReleaseMutex(cout_Mutex);
        SetEvent(hEvent);
    }
    return 0L;
};

DWORD WINAPI MyThread2(LPVOID lpParamter){

    THREAD_DATA *data = (THREAD_DATA *)lpParamter;
    for(int i = 0;i < data->maxnum;++i){
        WaitForSingleObject(hEvent,INFINITE);
        cout<<data->data<<"B"<<endl;
        //ReleaseMutex(cout_Mutex);
        SetEvent(hEvent);
    }
    return 0L;
}

int main(){

    THREAD_DATA thread_data1,thread_data2;
    thread_data1.maxnum = 5;
    thread_data1.data = "线程1----";
    thread_data2.maxnum = 5;
    thread_data2.data = "线程2----";

    cout_Mutex = CreateMutex(NULL,FALSE,NULL);
    hEvent = CreateEvent(NULL, FALSE, TRUE, NULL);

    HANDLE hThread1 = CreateThread(NULL,0,MyThread1,&thread_data1,0,NULL);
    HANDLE hThread2 = CreateThread(NULL,0,MyThread2,&thread_data2,0,NULL);
    CloseHandle(hThread1);
    CloseHandle(hThread2);
    system("pause");   
    return 0;
}
```



手写大小端转换函数 

手写socket断点续传文件

手撕智能指针

斐波那契数列 

二叉树的最大路径和、二叉树最大和的路径；

DFS、BFS

整数转化成字符串；

层次遍历二叉树的过程；

迭代二叉树的深度；

0-n-1中缺失的数字，两种方法；

二叉搜索树后序遍历；

IP地址字符串转换为32位整数；

两个有序数组，其中一个有足够空位，不使用额外空间排序到含空位数组中；

求二叉树两个节点的最小距离；

对大规模数据进行去重；

寻找无序整数数组中第一个缺失的正数；

对给出一个数组中的每个元素求因数个数；

二维数组回旋打印；