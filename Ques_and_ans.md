

## 1. 网络

#### IPV4跟IPV6比较

1. IPv4：



2. IPv6：

地址长度是128位，每16位是一组，中间用冒号‘：’隔开；连续的0可以用两个冒号来折叠，但只能用一次；

亮点：

- IPv6可以自动设置，即使没有DHCP服务也可以实现IP地址的自动分配；
- IPv6 包头包首部长度采用固定的值 `40` 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大**提高了传输的性能**。
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**。

#### 网桥工作在哪一层

- 物理层：双绞线、中继器、集线器
- 数据链路层：网桥、交换机（根据MAC地址寻址）、网卡
- 网络层：路由器（根据IP地址寻址）
- 应用层：网关；

**网桥**工作在数据链路层的介质访问控制(MAC)子层上,用于在多个使用同一种通信协议的网段中传送数据包的设备

#### 网关的作用是什么

网关（Gateway）又称网间连接器、协议转换器。网关在传输层上以实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关的结构也和路由器类似，不同的是互连层。网关既可以用于广域互连，也可以用于局域网互连。网关是一种充当转换重任的计算机系统或设备。在使用不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关也可以提供过滤和安全功能。大多数网关运行在OSI 7层协议的顶层–应用层。

那么网关到底是什么呢？网关实质上是一个网络通向其他网络的IP地址。比如有网络A和网络B，网络A的IP地址范围为`192.168.1.1~192.168.1.254`，子网掩码为`255.255.255.0`；网络B的IP地址范围为`192.168.2.1~192.168.2.254`，子网掩码为`255.255.255.0`。在没有路由器的情况下，两个网络之间是不能进行TCP/IP通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP协议也会根据子网掩码（`255.255.255.0`）判定两个网络中的主机处在不同的网络里。而要实现这两个网路之间的通信，则必须通过网关。如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机。

默认网关的意思是一台主机如果找不到可用的网关，就把数据包发给默认指定的网关，由这个网关来处理数据包。

#### 子网掩码详细作用？

主要是用来区分网络地址与主机地址；如果网络地址相同，则证明是在同一个网段，如果不同则需要借助路由的转发；

是由于IPv4的地址资源紧缺，做不到每个网络设备都能获得一个网络地址。可变长度的网络地址分配方式相比以前主类网络划分方式更加灵活，在有限的网址资源的情况下，提高网络地址的利用率，减少网络地址的浪费。而灵活的代价就是：网络地址可以改变长度，没有规律可循了，只能靠子网掩码来划分了，所以这就是子网掩码的用途：**区分网络地址和主机地址。**

在没有子网掩码之前，网络地址按照主类网络的方式进行区分，但是这种划分方式不够灵活，也很浪费地址资源，并且随着通信设备的普及，有上网需求的通信设备不断增加，并且online和offline之间的切换频繁，数量是随着时间变化而变化的。因此子网掩码的出现，在**划分地址资源**方面做出了改进。

#### OSI七层协议

分别是-物理层、数据链路层、网络层、传输层、会话层、表示层、应用层；

- 应用层：为应用程序提供服务；
  - FTP(21端口)：文件传输协议
  - SSH(22端口)：远程登陆
  - TELNET(23端口)：远程登录
  - SMTP(25端口)：发送邮件
  - POP3(110端口)：接收邮件
  - HTTP(80端口)：超文本传输协议
  - DNS(53端口)：运行在UDP上，域名解析服务
- 表示层：数据格式转化、数据加密；
- 会话层：建立、管理和维护会话；
- 传输层：建立、管理和维护端到端的连接；
- 网络层：IP选址与路由选择；
- 数据链路层：提供介质访问与链路管理；
- 物理层：通过物理介质传输比特流；

#### Get 与 Post区别？

- **GET**用于获取资源，**POST**用于传输实体主体；

- **参数方面：**GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具查看。因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 `中文` 会转换为 `%E4%B8%AD%E6%96%87`，而`空格`会转换为 `%20`。POST 参数支持标准字符集。

- **安全方面：**安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。

  安全的方法除了 GET 之外还有：HEAD、OPTIONS。

  不安全的方法除了 POST 之外还有 PUT、DELETE。

- **幂等性：**幂等性：同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。所有的安全的方法都是幂等的，在正确实现的情况下：GET、HEAD、PUT、DELETE等是幂等的，POST是非幂等的；

- **可缓存：**如果要对响应进行缓存，需要满足以下条件：

  - 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。
  - 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。
  - 响应报文的 Cache-Control 首部字段没有指定不进行缓存。

- 为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest：

  > XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。

  - 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。
  - 而 GET 方法 Header 和 Data 会一起发送。

#### Http与Https区别？

1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；
2. HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；
3. HTTPS由于加密解密会带来更大的CPU和内存开销；
4. HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买

#### HTTPS加密过程？

- 加密：
  - 对称密钥加密：对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。所以运算速度会非常快，但是无法安全的将密钥传输给通信方；
  - 非对称密钥加密：非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。
  - 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）
- HTTPS 采用混合的加密机制：
  - 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性;
  - 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key）
- 数字签名：
  - 非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。

#### Https的连接过程 *

1. 客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；
2. 服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，**加密公钥**（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；
3. 客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；
4. 如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个**随机密钥**（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行**摘要**计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；
5. 服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；
6. 浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密

总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。

#### HTTP的状态码

| 状态码 | 类别                             | 含义                       |
| ------ | -------------------------------- | -------------------------- |
| 1XX    | Informational（信息性状态码）    | 接收的请求正在处理         |
| 2XX    | Success（成功状态码）            | 请求正常处理完毕           |
| 3XX    | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 |
| 4XX    | Client Error（客户端错误状态码） | 服务器无法处理请求         |
| 5XX    | Server Error（服务器错误状态码） | 服务器处理请求出错         |

#### HTTP使用长连接有哪些优点？

- 减少握手的次数；
- 减少慢启动的影响；短链接的话要每一个连接都要经历从慢到快的那个过程，总体上时间要慢得多；
- 缺点：会有队头阻塞的问题，如果中间某个数据包丢失，那么即使后面的数据包传送过去了，接收端也不能够接收；

#### TLS/SSL协议是怎样保障信息安全的？

- PKI证书体系；
- 密钥交换协议；椭圆曲线
- 对称加密算法； 

#### HTTP2.0协议有哪些优点？

- HTTP1.1 的缺点：header太长了、长连接的情况下不支持多路复用；
- 多路复用、消息推送：把关联性的消息直接推送，
- header的编码：HPACK编码（动态表、静态表、静态Huffman、整数编码）
- stream优先级：父子依赖、权重

#### TCP\UDP的区别

1. TCP是面向连接的，UDP是无连接的；
2. TCP是可靠的，UDP不可靠；
3. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；
4. TCP是面向字节流的，UDP是面向报文的；
5. TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；
6. TCP首部开销（20字节）比UDP首部开销（8字节）要大；
7. UDP 的主机不需要维持复杂的连接状态表；

#### TCP为什么可靠

1. 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；
2. 对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；
3. 丢弃重复数据：对于重复数据，能够丢弃重复数据；
4. 应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；
5. 超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
6. 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

#### TCP三次握手

![三次握手.png-12.4kB](http://static.zybuluo.com/Rico123/c7m5fo6qdua0q7me88jm9w10/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png)

- 第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；
- 第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；
- 第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。

>TCP连接可以两次握手吗？

不可以，两方面的原因：

1. 可能会出现已经失效的连接请求报文段又发送到了服务端，比如说client发送的一个连接请求报文段在传输过程中并没有丢失，而是在某个网络节点拥塞并滞留了一段时间， 导致报文段延误到连接释放之后才到达服务器，这样服务器收到了一个原本是失效的报文段，但是服务器不知道，会误认为是client发送的新的连接请求，所以就会向client发送确认报文段建立连接，如果是两次握手，那么现在就成功建立了连接，但实际client端并没有发送新的建立连接的请求，也就不会理睬服务器的确认报文段，不会向服务器发送数据。而服务器端以为已经建立好了连接，就会一直等待client发送数据，导致服务器资源的浪费；三次握手就可以解决这样的问题，在client收到服务器确认报文段时，不会向服务器的确认发送确认，服务器收不到确认，连接也就不能建立；
2. 两次握手无法保证client正确的收到服务器发送的确认报文，也无法保证client与服务器端之间成功交换初始序列号；

> 可以采用四次握手吗？

- 可以，但是三次握手可以搞定的事情，用四次握手才搞定，就会降低传输的效率；多出来的一次是将第二次服务器到客户端的确认报文拆分为两次传输，第一次服务器只发送ACK与acknowledge number的确认报文段，而服务器端的SYN与初始序列号在第三次握手的时候发送；

> 第三次握手中，如果客户端的ACK报文段没有成功发送到服务器端，会发生什么？

- 服务器端：由于没有收到ACK确认，会重复发送第二次握手的报文段，（默认是重发5次，然后会自动关闭连接，进入closed状态），在客户端收到重发的报文段后会重新传ACK给服务器端；
- 客户端：1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态；2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。

> 建立连接后，如果客户端出现了故障会怎么样？

- 服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

> 什么是初始序列号？

- TCP连接的一方，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），以该序列号为原点，对要传送的数据进行编号. 三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节。

#### TCP四次挥手

- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入**FIN_WAIT_1**状态；
- 第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入**CLOSE_WAIT**状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据，客户端进入**FIN_WAIT_2**的状态。
- 第三次挥手：Server将FIN置1，发送一个序列号给Client，进入**LAST_ACK**状态，客户端进入**TIME_WAIT**状态；
- 第四次挥手：Client收到服务器的FIN后，进入**TIME_WAIT**状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为**CLOSED**状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入**CLOSED**状态。完成四次挥手。

> 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？

- 因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。
- close_wait可以存在的时间可以非常的长，因为TCP允许全双工，可以进入半打开的状态；只有一端可以发消息，另一端不可以发了，这个时候就会进入closed_wait的状态；当然实际情况下，长时间使用这种状态的连接是很少的，当用netstate命令看到了close_wait，一半以上就是出bug了；

> 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

- 客户端没有收到ACK确认，会重新发送FIN请求。

> 客户端TIME_WAIT状态的意义是什么？

- 第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。
- MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

#### TCP滑动窗口机制

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。

发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

> 接收窗口为0会怎么样？零窗口

- 如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。

#### TCP拥塞控制机制

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

TCP 主要通过四个算法来进行拥塞控制：`慢开始、拥塞避免、快重传、快恢复`。

发送方需要维护一个叫做**拥塞窗口（cwnd）**的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。

为了便于讨论，做如下假设：

- 接收方有足够大的接收缓存，因此不会发生流量控制；
- 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。

1. 慢开始与拥塞避免

发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

2. 快重传与快恢复

在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。

在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。

在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

#### TCP和UDP分别对应的常见应用层协议

1). TCP对应的应用层协议

- FTP：定义了文件传输协议，使用21端口。常说某某计算机开了FTP服务便是启动了文件传输服务。下载文件，上传主页，都要用到FTP服务。
- Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于DOS模式下的通信服务。如以前的BBS是-纯字符界面的，支持BBS的服务器将23端口打开，对外提供服务。
- SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么SMTP端口设置这个栏，服务器开放的是25号端口。
- POP3：它是和SMTP对应，POP3用于接收邮件。通常情况下，POP3协议所用的是110端口。也是说，只要你有相应的使用POP3协议的程序（例如Fo-xmail或Outlook），就可以不以Web方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。
- HTTP：从Web服务器传输超文本到本地浏览器的传送协议。

2). UDP对应的应用层协议

- DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。
- SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。
- TFTP(Trival File Transfer Protocal)：简单文件传输协议，该协议在熟知端口69上使用UDP服务。

#### URL请求到渲染的过程

浏览器解析URL->生成发送给Web服务器的请求信息（HTTP请求信息）->查询服务器域名对应的IP地址（DNS）-> 发起client到server的连接请求（TCP三次握手） -> 连接建立之后由client向server发送HTTP请求信息 -> 服务器处理请求信息，并将结果返回给浏览器 -> 浏览器完成解析并渲染

1. 浏览器解析URL，先要通过网站的域名查询域名对应的IP地址；
2. 生成DNS查询报文，并放入目的地址为DNS服务器IP地址的IP数据报中，IP数据报放入以太网帧中，如果这时还不知道网关的MAC地址，可能还需要ARP协议的帮助来获取网关的MAC地址；
3. 收到来自DNS服务器的应答报文之后，解析出域名地址对应的IP地址；
4. 有了HTTP服务器的IP地址之后，主机通过TCP三次握手来与HTTP服务器建立连接；
5. 主机生成TCP套接字，并且生成HTTP GET报文，发送给HTTP服务器；
6. HTTP服务器从TCP套接字读取GET报文，生成一个HTTP响应报文，返回给浏览器；
7. 浏览器收到HTTP响应报文后，解析内容后进行渲染，显示出相应的Web页面；

#### DNS协议

DNS域名解析协议就是将域名地址转换为IP地址；

域名层级之间靠句点`"."`来分割，越靠右边的域名层级越高；

- 域名层级关系：
  - 根DNS服务器
  - 顶级域DNS服务器
  - 权威DNS服务器
- 工作流程：
  - 客户端发送DNS请求，发送给本地DNS服务器；
  - 本地域名服务器：如果能够在缓存表中找到域名的IP地址，则直接返回IP地址；如果没有，本地DNS会发送信息到根域名服务器；
  - 根DNS服务器：根据域名给出顶级域名服务器地址，并发送给本地域名服务器；
  - 本地域名服务器收到地址后发送信息给顶级域名服务器；
  - 顶级域名服务器将权威域名服务器地址发送给本地域名服务器；
  - 本地域名服务器发送信息给权威域名服务器；
  - 权威域名服务器将IP地址发送给本地域名服务器；
  - 本地域名服务器将IP地址返回给客户端；

#### ARP协议

ARP 地址解析协议，作用是在以太网环境中，数据的传输所依懒的是`MAC地址`而非`IP地址`，而将已知`IP地址`转换为`MAC地址`的工作是由`ARP协议`来完成的。每个主机都会有一个`ARP高速缓存`，里面有所在的局域网上的各主机和路由器的IP地址到硬件地址的`映射表`。

数据包在确定源IP地址与目的IP地址之后，会通过主机的路由表来确定数据包的下一跳的IP地址，但是数据链路层需要的是下一跳的MAC地址，因此借助ARP协议可以完成IP地址到MAC地址的转换，具体过程如下：

- ARP协议借助ARP请求与ARP响应两种包来确定MAC地址；
- 主机通过广播发送ARP请求包，包中含有想知道的MAC地址对应的IP地址；
- 同链路中设备收到ARP请求包后将会解析ARP请求包中的目标IP地址，如果匹配将会返回含有自己MAC地址的ARP响应包给主机；
- 操作系统会建立一个所在局域网上各设备的IP地址到MAC地址的映射表，并会定期清理映射表中的内容；

> RARP协议：ARP协议的逆协议，作用是根据MAC地址转换为IP地址；
>
> 如果是小型嵌入式设备接入网络，则通常需要一台RARP服务器来协助其完成IP设置，服务器中注册该设备的MAC地址与IP地址，然后将该设备接入网络，随后就会发送一条MAC地址到IP地址的RARP请求包，服务器则会将查询到的IP地址通过相应包发送给设备，协助其完成IP地址设置；

#### ICMP协议

ICMP(internet control message protocol)网际控制报文协议，目的是提高IP数据报交付成功的机会。ICMP属于IP层协议，允许主机或路由器报告差错情况和提供有关异常情况的报告，测试网络层有没有故障。

功能：确认IP包是否成功送达目标地址、报告发送过程中IP包被废弃的原因、改善网络设置等；

1. ICMP报文格式

> 首先，ICMP报文是封装在IP包里面的，作为IP包的数据部分存在，是TCP/IP协议中IP协议的助手；

类型（8位）：ICMP查询报文（用于诊断）、ICMP差错报告报文（通知出错原因）

```c++
/*
查询报文类型：<类型号-内容>   0-回送应答、8-回送请求

类型号（8位）：0、8;
代码（8位）：0;
校验和（16位）：
标识符（16位）：用以区分是哪个进程发送的ICMP包，比如使用进程PID作为标识符;
序号（16位）：序号从0开始，每发送一次新的回送请求就会加1，可以用来确认网络包是否有丢失;
选项数据：具体情况而定，ping会存放发送请求的时间，来计算往返时间；
```

```c++
/*
差错报文类型：<类型号-内容>   3-目标不可达、4-原点抑制、5-重定向或改变路由、11-超时

类型号（8位）：3、4、5、11

//类型号 3 目标不可达消息
IP路由器无法将IP数据包发送给目标地址时，返回发送端主机一个目标不可达的ICMP消息
 在ICMP包头的代码字段中记录具体不可达原因；
 0-网络不可达；
 1-主机不可达；
 2-协议不可达；
 3-端口不可达；
 4-需要进行分片但设置了不分片；
//类型号 4 原点抑制消息
ICMP原点抑制是为了缓解低速广域线路下，路由器可能会遇到网络拥堵的问题；
 具体来说就是当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向IP包的源地址发送一个ICMP原点抑制消息；收到该包的主机会增大IP包的传输间隔，减少网络拥堵的状况；
//类型号 5 重定向消息
如果路由器发现发送端使用了非最优路径发送数据，它会返回一个ICMP重定向消息给主机；
 消息中包含最合适的路由信息和源数据；
//类型号 11 超时消息
如果IP包中的TTL值在当前路由器中减为0，则该IP包被丢弃，并且发送一个ICMP超时消息给发送端主机；
```

ping的过程：

1. 源主机先构建一个ICMP回送请求消息数据包，类型号为8，并且还有序号，每发一个请求数据包，序号自动加1，并且在报文数据部分插入发送时间，以方便计算往返时间RTT；
2. 由ICMP协议将数据包与目的IP地址交给IP层，IP层构建一个协议字段为1的IP数据包；
3. 从本地ARP映射表中查询或者利用ARP协议查询目的MAC地址，通过数据链路层构建一个数据帧并发送出去；

4. 目的端收到数据帧后，查验目的MAC地址，匹配则接收，否则丢弃；
5. 提取数据帧中的IP数据包，IP层检查后将有用的信息提取交给ICMP协议；
6. 目的端主机会构建一个ICMP回送响应消息数据包，类型为0，序号为请求数据包中的序号，发送给源端主机；

- 源端如果在规定时间内没有收到ICMP应答包，则说明目标主机不可达，收到应答包后，会用当前时刻减去数据包发送时刻，得到数据包的延迟；

traceroute的作用：

1. 通过故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器；
2. 利用traceroute可以知道发出的UDP包是否到达了目的主机；
3. traceroute可以通过故意设置不分片，来确定路径的MTU；

#### IGMP协议



#### DHCP协议

DHCP协议用于动态获取IP地址；具体步骤为：（本部分来自小林coding）

- 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 `255.255.255.255`（端口 67） 并且使用` 0.0.0.0`（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
- DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 `255.255.255.255`，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
- 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST）**进行响应，回显配置的参数。
- 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

- 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

所以在DHCP 交互中**全程都是使用 UDP 广播通信**。

> 对于客户端与DHCP服务器不在同一局域网内的情况，需要用到DHCP中继代理：
>
> - DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
> - 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包转发给 DHCP 客户端 。
>
> 因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址。

#### 客户端不断进行请求链接会怎样？DDos攻击

1)、DDos 攻击

- 客户端向服务端发送请求链接数据包
- 服务端向客户端发送确认数据包
- 客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认

2)、DDos 预防 **( 没有彻底根治的办法，除非不使用TCP )**

- 限制同时打开SYN半链接的数目
- 缩短SYN半链接的Time out 时间
- 关闭不必要的服务

------

## 2. 操作系统

#### 进程与线程的区别是啥

- 进程：进程是系统进行资源分配的基本单位，进程的基本信息与状态由进程控制块PCB来描述；

  - 程序 = 算法 + 数据结构（描述进程的数据结构：进程控制块PCB） 

- 线程：线程是CPU调度的基本单位，是进程当中的一条执行流程，同时线程依赖于进程存在，一个进程至少有一个线程存在；`线程=进程-共享资源`

  - 线程能够减少并发执行的时间和空间开销：
    - 线程的创建时间比进程短；
    - 线程的终止时间比进程短
    - 同一进程内的线程切换时间比进程短
    - 由于同一进程的各线程之间共享内存和文件资源，可直接进行不通过内核的通信；

- 区别：
  - 进程是系统资源分配的基本单位，因此线程只拥有一点再运行中必不可少的资源，如程序计数器、寄存器、栈等，其余的资源需要访问隶属进程的资源；

  - 线程是CPU调度的最小单位，因此同一个进程中的线程切换只需要保存和设置少量的寄存器内容，而不属于同一个进程的线程之间的切换，涉及到进程切换，需要当前执行进程CPU环境的保存及新调度进程CPU环境的设置，相对来说进程切换的开销远大于线程切换的开销；`线程有自己的寄存器和堆栈`

  - 通信方面，线程之间的通信可以通过同一进程中的共享数据通信，而进程之间的通信需要借助IPC；

  - 稳定性方面，多线程程序如果有一个线程对共享数据造成破坏或崩溃，会影响整个程序，导致崩溃，但是在多进程程序中，进程间是相互独立的，一个进程出错或崩溃不会导致整个程序崩溃，所以在稳定性和健壮性方面，多进程更好；`进程更安全，但是慢一点，线程快，性能好，但是不够安全`

#### 线程的实现方式？有什么区别？*

  C++ 静态局部变量 能保证线程安全 

  问了别的方式std::call_once或者静态成员变量，但是一般都会用静态局部变量 

  C++没有java的volatile能阻止指令重排，不能用DCL 

#### 进程通信方法

1. 管道pipe
   - 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。
   - 只支持半双工通信（单向交替传输）；
   - 只能在父子进程或者兄弟进程中使用。
2. 命名管道FIFO
   - 去除了管道只能在父子进程中使用的限制。
   - FIFO常用于客户-服务器（C/S）应用程序中，FIFO用作汇聚点，在客户进程和服务器进程之间传递数据。
3. 消息队列
   - 消息队列是按照FIFO来管理消息的；
   - 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
   - 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
   - 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。
4. 信号量
   - 信号量是一个整型变量sem，包含两个原子操作P( )、V( )，也就是对信号量的-1和+1操作；
   - 当一个线程访问临界区，信号量为正，则可以进行P操作，如果信号量等于0，则线程睡眠，等待信号量大于0；如果一个线程完成了对临界区的访问，会对信号量执行V操作，信号量+1，同时会唤醒睡眠的线程；
   - 信号量是被保护的变量，在初始化完成后，唯一改变一个信号量的值的办法就是通过P、V操作；
   - P操作能够产生阻塞，V操作不会阻塞；
   - 信号量允许同一时刻多个线程访问同一资源，最大线程数量不超过信号量的最大资源计数；
   - 如果信号量的最大资源计数为1，也就是只能取0和1，那么信号量就成了互斥量；
5. 共享内存
   - 也称为直接通信模式；
   - 每个进程都有私有地址空间，在每个地址空间内，明确的设置了`共享内存段(多个进程可以将同一个文件映射到它们的地址空间，也就是映射到共享内存段，从而实现共享内存)`；允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC，并且一个进程写，另一个进程立即可见，没有系统调用干预，没有数据的复制；
   - 该方法能够快速、方便的共享数据，但是必须同步数据访问，以免产生冲突（常利用`信号量`来实现同步）；
6. 套接字
   - 与其它通信机制不同的是，它可用于不同机器间的进程通信。

#### 进程同步方法

> 什么是同步：同步就是数据保持一致，无论是进程还是线程，都是实现了代码执行流程的分支，多个分支同时进行。多个分支互不干扰，但是又有些数据需要共享，让这些数据对所有分支保持一致即为同步。 
>
> 什么是通信：通信就是数据传输，数据存在两块不同的内存区域。通过某种方式互相传递。

- 进程的同步是目的，而进程间通信是实现进程同步的手段;

1. 信号量semaphore :信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。当它的值大于0时，表示当前可用资源的数量；当它的值小于0时，其绝对值表示等待使用该资源的进程个数。注意，信号量的值仅能由PV操作来改变。	

   - PV操作是典型的同步机制之一。用一个信号量与一个消息联系起来，当信号量的值为0时，表示期望的消息尚未产生；当信号量的值非0时，表示期望的消息已经存在。用PV操作实现进程同步时，调用P操作测试消息是否到达，调用V操作发送消息。

   -   使用PV操作实现进程同步时应该注意的是：

       （1）分析进程间的制约关系，确定信号量种类。在保持进程间有正确的同步关系情况下，哪个进程先执行，哪些进程后执行，彼此间通过什么资源（信号量）进行协调，从而明确要设置哪些信号量。
       （2）信号量的初值与相应资源的数量有关，也与P、V操作在程序代码中出现的位置有关。
       （3）同一信号量的P、V操作要成对出现，但它们分别在不同的进程代码中。

2. 管程:集中式同步进程，其基本思想是将共享变量和对它们的操作集中在一个模块中，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，易于保证正确性。

   - 从语言的角度看，管程主要有以下特性： 

     （1）模块化。管程是一个基本程序单位，可以单独编译; 

     （2）抽象数据类型。管程是中不仅有数据，而且有对数据的操作; 

     （3）信息掩蔽。管程外可以调用管程内部定义的一些函数，但函数的具体实现外部不可见; 

   - 为了保证共享变量的数据一致性，管程应互斥使用。 管程通常是用于管理资源的，因此管程中有`进程等待队列`和相应的`等待和唤醒操作`。在管程入口有一个等待队列，称为`入口等待队列`。当一个已进入管程的进程等待时，就释放管程的互斥使用权；当已进入管程的一个进程唤醒另一个进程时，两者必须有一个退出或停止使用管程。在管程内部，由于执行唤醒操作，可能存在多个等待进程（等待使用管程），称为`紧急等待队列`，它的优先级高于入口等待队列。

   - 因此，一个进程进入管程之前要先申请，一般由管程提供一个`enter`过程；离开时释放使用权，如果紧急等待队列不空，则唤醒第一个等待者，一般也由管程提供外部过程`leave`。

   - 管程内部有自己的等待机制。管程可以说明一种特殊的条件型变量：var c:condition；实际上是一个指针，指向一个等待该条件的PCB队列。对条件型变量可执行`wait`和`signal`操作：（联系P和V； take和give） 

   - `wait(c)`:若紧急等待队列不空，唤醒第一个等待者，否则释放管程使用权。执行本操作的进程进入C队列尾部； 

   - `signal(c)`:若C队列为空，继续原进程，否则唤醒队列第一个等待者，自己进入紧急等待队列尾部。 

#### 线程通信方法

线程里数据是共享的，即同一变量占用同一个内存地址，所以用全局变量就可以轻松实现数据交流。

#### 线程同步方法

> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。
>
> 从大的方面讲，线程的同步可分`用户模式的线程同步`和`内核对象的线程同步`两大类。
>
> - 用户模式中线程的同步方法主要有`原子访问`和`临界区`等方法。其特点是同步速度特别快，适合于对线程运行速度有严格要求的场合。
> - 内核对象的线程同步则主要由`事件`、`等待定时器`、`互斥量`、`信号量`等内核对象构成。由于这种同步机制使用了内核对象，使用时必须将线程从用户模式切换到内核模式，而这种转换一般要耗费近千个CPU周期，因此同步速度较慢，但在适用性上却要远优于用户模式的线程同步方式。

1. 互斥量Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资源，更有效率。

   ```c++
   HANDLE CreateMutex(
     LPSECURITY_ATTRIBUTESlpMutexAttributes,//表示安全控制，一般直接传入NULL。
     BOOLbInitialOwner,//用来确定互斥量的初始拥有者。如果传入TRUE表示互斥量对象内部会记录创建它的线程的线程ID号并将递归计数设置为1，由于该线程ID非零，
      //所以互斥量处于未触发状态。如果传入FALSE，那么互斥量对象内部的线程ID号将设置为NULL，递归计数设置为0，这意味互斥量不为任何线程占用，处于触发状态。 
     LPCTSTRlpName//用来设置互斥量的名称，在多个进程中的线程就是通过名称来确保它们访问的是同一个互斥量。
   );
   HANDLE OpenMutex(
    DWORDdwDesiredAccess,//表示访问权限，对互斥量一般传入MUTEX_ALL_ACCESS。
    BOOLbInheritHandle,//表示互斥量句柄继承性，一般传入TRUE即可。
    LPCTSTRlpName     //表示名称。某一个进程中的线程创建互斥量后，其它进程中的线程就可以通过这个函数来找到这个互斥量。
   );//成功返回一个表示互斥量的句柄，失败返回NULL。
   BOOL ReleaseMutex (HANDLE hMutex)//访问互斥资源前应该要调用等待函数，结束访问时就要调用ReleaseMutex()来表示自己已经结束访问，其它线程可以开始访问了。
   //由于互斥量是内核对象，因此使用CloseHandle()就可以
       
   //mutex用于线程所有权因此必须由得到Mutex所有权的主线程调用ReleaseMutex才行，而Event没有所谓线程所有权因此只需在线程函数里SetEvent（），所以Mutex不能实现同步.
   //
   ```

   **未触发其实就是已经有线程独占了,所以其它线程就只能等待;当该线程释放互斥量后,也就是互斥量中的线程ID为0,计数器为0,这时,互斥量处于触发状态,其它线程可以进入,从而拥有该互斥量对象了;**

   mutex的线程相关性导致无法进行线程同步。而event是线程无关的；

2. 信号量Semaphore：
   - 信号量是一个整型变量sem，包含两个原子操作P( )、V( )，也就是对信号量的-1和+1操作；
   - 当一个线程访问临界区，信号量为正，则可以进行P操作，如果信号量等于0，则线程睡眠，等待信号量大于0；如果一个线程完成了对临界区的访问，会对信号量执行V操作，信号量+1，同时会唤醒睡眠的线程；
   - 信号量是被保护的变量，在初始化完成后，唯一改变一个信号量的值的办法就是通过P、V操作；
   - P操作能够产生阻塞，V操作不会阻塞；
   - 信号量允许同一时刻多个线程访问同一资源，最大线程数量不超过信号量的最大资源计数；
   - 如果信号量的最大资源计数为1，也就是只能取0和1，那么信号量就成了互斥量；

   ```c++
   HANDLE CreateSemaphore(
     LPSECURITY_ATTRIBUTES lpSemaphoreAttributes,//表示安全控制，一般直接传入NULL。
     LONG lInitialCount,//表示初始资源数量。
     LONG lMaximumCount,//表示最大并发数量。
     LPCTSTR lpName//表示信号量的名称，传入NULL表示匿名信号量。
   );
   HANDLE OpenSemaphore(
     DWORD dwDesiredAccess,//表示访问权限，对一般传入SEMAPHORE_ALL_ACCESS。
     BOOL bInheritHandle,//表示信号量句柄继承性，一般传入TRUE即可。
     LPCTSTR lpName//表示名称，不同进程中的各线程可以通过名称来确保它们访问同一个信号量。
   );
   BOOL ReleaseSemaphore(//递增信号量的当前资源计数
     HANDLE hSemaphore,//信号量的句柄。
     LONG lReleaseCount,  //表示增加个数，必须大于0且不超过最大资源数量。
     LPLONG lpPreviousCount //用来传出先前的资源计数，设为NULL表示不需要传出。
   );
   //由于信号量是内核对象，因此使用CloseHandle()就可以完成清理与销毁了。
   ```
   
   **当前资源数量大于0，表示信号量处于触发，等于0表示资源已经耗尽故信号量处于末触发。**在对信号量调用等待函数时，等待函数会检查信号量的当前资源计数，如果大于0(即信号量处于触发状态)，减1后返回让调用线程继续执行。一个线程可以多次调用等待函数来减小信号量。 
   
3. 事件Event（信号）：
   - 允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后自动恢复为未激发状态。

   - 事件对象状态：有信号状态、无信号状态；

   - 事件对象类型：人工事件(手动设置)、自动事件(自动恢复)；

   - 自动事件对象，在被至少一个线程释放后自动返回到无信号状态；

   - 人工事件对象，获得信号后，释放可利用线程，但直到调用成员函数ReSet()才将其设置为无信号状态。在创建Cevent对象时，默认创建的是自动事件。

   - 使用”事件”机制应注意以下事项：

     （1）如果跨进程访问事件，必须对事件命名，在对事件命名的时候，要注意不要与系统命名空间中的其它全局命名对象冲突；

     （2）事件是否要自动恢复；

     （3）事件的初始状态设置。

     ```c++
     HANDLE CreateEvent(
     LPSECURITY_ATTRIBUTES lpEventAttributes,//表示安全控制，一般直接传入NULL。
     BOOL bManualReset,//确定事件是手动置位还是自动置位，传入TRUE表示手动置位，传入FALSE表示自动置位。
     BOOL bInitialState,//表示事件的初始状态，传入TRUR表示已触发。
     LPCSTR lpName//表示事件的名称，传入NULL表示匿名事件。
     );
     HANDLE OpenEvent(
      DWORDdwDesiredAccess,//表示访问权限，对事件一般传入EVENT_ALL_ACCESS。
      BOOLbInheritHandle,//表示事件句柄继承性，一般传入TRUE即可。
      LPCTSTRlpName     //表示名称，不同进程中的各线程可以通过名称来确保它们访问同一个事件。
     );
     //bManualReset:TRUE，使用ResetEvent()手动重置为无信号状态；FALSE，当一个等待线程被释放时,自动重置状态为无信号状态。
     //bInitialState：指定事件对象的初始状态，当TRUE,初始状态为有信号状态；当FALSE,初始状态为无信号状态。
     BOOL SetEvent(HANDLEhEvent);//设置事件为触发；（解锁）每次触发后，必有一个或多个处于等待状态下的线程变成可调度状态。
     BOOL ResetEvent(HANDLEhEvent);//将事件设为末触发（加锁）
     //由于事件是内核对象，因此使用CloseHandle()就可以完成清理与销毁了。
     
     #include "stdafx.h"
     #include<windows.h>
     #include<iostream>
     using namespace std;
     
     int number = 1;	//定义全局变量
     HANDLE hEvent;	//定义事件句柄
     
     unsigned long __stdcall ThreadProc1(void* lp) {
     	while (number < 100) {
     		WaitForSingleObject(hEvent, INFINITE);	//等待对象为有信号状态
     		cout << "thread 1 :"<<number << endl;
     		++number;
     		_sleep(100);
     		SetEvent(hEvent);
     	}
     	return 0;
     }
     
     unsigned long __stdcall ThreadProc2(void* lp) {
     	while (number < 100) {
     		WaitForSingleObject(hEvent, INFINITE);	//等待对象为有信号状态
     		cout << "thread 2 :"<<number << endl;
     		++number;
     		_sleep(100);
     		SetEvent(hEvent);
     	}
     	return 0;
     }
     int main() {
       	hEvent = CreateEvent(NULL, FALSE, TRUE, "event");
       	CreateThread(NULL, 0, ThreadProc1, NULL, 0, NULL);
       	CreateThread(NULL, 0, ThreadProc2, NULL, 0, NULL);
       	Sleep(10*1000);
       	system("pause");
           return 0;
       }
     ```

4. 临界区Critical Section：

   - 一段对临界资源访问的代码，称为临界区；临界区只允许`同时一个线程`对其访问，如果同时有其他线程试图访问临界区，会被挂起，直到临界区中的线程退出临界区；`临界区是指线程中的一段需要访问共享资源并且当另一个线程处于相应代码区域时便不会被执行的代码区域.`

   - 临界区在使用时以`CRITICAL_SECTION`结构对象保护共享资源，并分别用`EnterCriticalSection()`和`LeaveCriticalSection()`函数去标识和释放一个临界区。所用到的`CRITICAL_SECTION`结构对象必须经过`InitializeCriticalSection()`的初始化后才能使用，而且必须确保所有线程中的任何试图访问此共享资源的代码都处在此临界区的保护之下。否则临界区将不会起到应有的作用，共享资源依然有被破坏的可能

     ```c++
     //函数
     void InitializeCriticalSection(LPCRITICAL_SECTIONlpCriticalSection);//临界区的初始化
     void DeleteCriticalSection(LPCRITICAL_SECTIONlpCriticalSection);//临界区的销毁
     void EnterCriticalSection(LPCRITICAL_SECTIONlpCriticalSection);//进入临界区
     void LeaveCriticalSection(LPCRITICAL_SECTIONlpCriticalSection);//离开临界区
     
     //
     #include "stdafx.h"
     #include<windows.h>
     #include<iostream>
     using namespace std;
     
     int number = 1;	//定义全局变量
     CRITICAL_SECTION Critical;		//定义临界区句柄
     
     unsigned long __stdcall ThreadProc1(void* lp) {
     	while (number < 100) {
     		EnterCriticalSection(&Critical);
     		cout << "thread 1 :"<<number << endl;
     		++number;
     		_sleep(100);
     		LeaveCriticalSection(&Critical);
     	}
     	return 0;
     }
     
     unsigned long __stdcall ThreadProc2(void* lp) {
     	while (number < 100) {
     		EnterCriticalSection(&Critical);
     		cout << "thread 2 :"<<number << endl;
     		++number;
     		_sleep(100);
     		LeaveCriticalSection(&Critical);
     	}
     	return 0;
     }
     
     int main() {
     	InitializeCriticalSection(&Critical);	//初始化临界区对象
     	CreateThread(NULL, 0, ThreadProc1, NULL, 0, NULL);
     	CreateThread(NULL, 0, ThreadProc2, NULL, 0, NULL);
     	Sleep(10*1000);
     	system("pause");
         return 0;
     }
     ```

5. 条件变量：

#### 生产者-消费者问题

1. 一个生产者、一个消费者、共用一个缓冲区；

   

2. 一个生产者、一个消费者、共用n个环形缓冲区；

   

3. 一组生产者，一组消费者，公用n个环形缓冲区；

   

#### 操作系统调度方法（进程调度方法）

1. 先来先服务FCFS
   - 如果进程在执行中阻塞，那么队列中的下一个会得到CPU；
   - 该调度方法非常的简单，但是平均等待时间波动较大，花费时间少的任务可能排在花费时间长的任务后面；
2. 最短作业优先SJF
   - 按照预测的完成时间来将任务入队；（非抢占）
   - 该调度算法拥有最优平均等待时间，但是可能导致饥饿，比如连续的短任务可能会使长任务饥饿，另外就是需要预知未来，需要预估下一个CPU突发的持续时间；
3. 最短剩余时间优先SRT
   - 按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；可能导致饥饿问题，对长进程不利。
4. 最高响应比优先HRRN
   - 在SJF的基础上，考虑到了饥饿现象（不可抢占、关注进程等待了多长时间、防止无限期推迟）；
   - R = (w + s) / s，选择R值最高的进程进入CPU，w是等待时间、s是执行时间；
   - 不可抢占、同样需要执行时间s，所以难以获得精确的时间，只能预估；
5. 时间片轮转
   - 将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；
   - 若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证，极限情况下退化为FCFS。
6. 优先级调度算法
   - 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
7. 多级反馈队列调度算法MFQ
   - 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

#### 基于优先级调度的方法存在什么问题

优先级调度可能会产生饥饿的问题，解决方法是偶尔提升一下优先级

#### 程序跟进程比较，是否一一对应

程序是静态的代码，进程是程序运行时产生的活动，启动一个程序的时候会产生一个或多个进程；

#### 进程线程地址空间



#### 虚拟内存VIRT、常驻内存RES、共享内存SHR？实际内存怎么计算？

VIRT：进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据，以及malloc、new分配的堆空间和分配的栈空间等；

RES：进程当前使用的内存大小，包括使用中的malloc、new分配的堆空间和分配的栈空间，但不包括swap out量；

SHR：除了自身进程的共享内存，也包括其他进程的共享内存；虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小；

- 虚拟内存是操作系统内核为了对进程地址空间进行管理（process address space management）而精心设计的一个逻辑意义上的内存空间概念。我们程序中的指针其实都是这个虚拟内存空间中的地址。因为这时候程序还没有运行，何谈物理内存空间地址？凡是程序运行过程中可能需要用到的指令或者数据都必须在虚拟内存空间中。虚拟内存与物理内存之间的映射机制就是页映射表，页映射表的基本原理是将程序运行过程中需要访问的一段虚拟内存空间通过页映射表映射到一段物理内存空间上，这样CPU访问对应虚拟内存地址的时候就可以通过这种查找页映射表的机制访问物理内存上的某个对应的地址。在程序运行过程中虚拟内存空间中需要被访问的部分会被映射到物理内存空间中。虚拟内存空间大只能表示程序运行过程中可访问的空间比较大，不代表物理内存空间占用也大。

- 驻留内存，顾名思义是指那些被映射到进程虚拟内存空间的物理内存。上图1中，在系统物理内存空间中被着色的部分都是驻留内存。比如，A1、A2、A3和A4是进程A的驻留内存；B1、B2和B3是进程B的驻留内存。进程的驻留内存就是进程实实在在占用的物理内存。一般我们所讲的进程占用了多少内存，其实就是说的占用了多少驻留内存而不是多少虚拟内存。因为虚拟内存大并不意味着占用的物理内存大。

- SHR是share（共享）的缩写，它表示的是进程占用的共享内存大小。程序中的一些动态库在内存中仅仅会保存/映射一份，如果某个进程运行时需要这个动态库，那么动态加载器会将这块内存映射到对应进程的虚拟内存空间中。多个进程之间通过共享内存的方式相互通信也会出现这样的情况。这么一来，就会出现不同进程的虚拟内存空间会映射到相同的物理内存空间。这部分物理内存空间其实是被多个进程所共享的，所以我们将他们称为共享内存，用SHR来表示。

- 一个进程的实际内存也就是进程的独占内存，计算方式为：驻留内存RES-共享内存SHR；

#### 既然多优先级队列+时间片轮转调度这么好，为什么还会出现死机情况?



#### 系统调用的过程

由于系统的有限资源可能被多个不同的应用程序访问，因此，如果不加以保护，那么用程序难免产生冲突。所以，现代操作系统都将可能产生冲突的系统资源给保护起来，阻止应用程序直接访问。这些系统资源包括文件、网络、IO、各种设备等。为了让应用程序有能力访问系统资源，也为了让应用程序能够借助操作系统做一些必须由操作系统支持的行为。每个操作系统都会提供一套接口，以供应用程序使用。这些接口往往通过中断来实现。

由于中断号是有限的，操作系统不舍得每一个系统调用对应一个中断号，而更倾向于用一个或少数几个中断号来对应所有的系统调用。Linux则使用int 0x80来触发所有系统调用。每个系统调用对应一份**系统调用号**，这个系统调用号在执行**int 0x80**指令前会放置在某个固定的寄存器里（eax)，对应的中断代码会取得这个系统调用号，并且调用正确的函数。

![img](https://img-blog.csdnimg.cn/20200709211508661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2ODIyMjE3,size_16,color_FFFFFF,t_70)

用户运行库函数（系统调用的封装），函数里面其实是执行的int 0x80指令。系统调用先把系统调用号保存在eax寄存器中，然后执行int0x80指令。int 0x80指令先进行切换堆栈（找到进程的堆栈，将寄存器值压入到内核栈中，将esp，ss设置成对应内核栈的值），查找相应中断向量的中断处理程序(system_call)并调用，随后system_call 从系统调用表中找到相应的系统调用进行调用，调用结束后从system_call中返回。

![img](https://img-blog.csdnimg.cn/20200712204654806.png)

#### 产生死锁的原因 

1. 竞争不可剥夺的资源
2. 进程间的调度顺序存在问题

- 产生死锁的四个必要条件：
  - 互斥：在一个时间只能有一个进程使用资源；
  - 持有并等待：进程保持至少一个资源正在等待获取其它进程持有的额外资源；
  - 无抢占：一个资源只能被进程自愿释放，不能被抢占；
  - 循环等待：多个进程组成了一条环路，循环等待下一个进程所持有的资源；`死锁必有环，有环不一定死锁`

#### 处理死锁的方法

- **鸵鸟策略**：忽略死锁问题；

- **死锁避免** `确保系统永远不进入不安全状态`

  ​	**安全状态**：

  - 需要系统具有一些额外的先验信息提供，最简单和最有效的模式是要求每个进程声明它可能需要的每个类型资源的最大数目；
  - 资源的分配状态是通过限定`提供与分配的资源数量`和`进程的最大需求`；
  - 死锁避免算法动态检查资源分配状态，以确保永远不会有一个环形等待状态（不安全状态）；
  - 当一个进程请求可用资源，系统必须判断立即分配 是否能使系统处于安全状态；

- **死锁预防**  `至少破坏一个产生死锁的条件`

  - 互斥：
  - 持有并等待：需要进程请求并分配其所有资源，它开始执行之前或允许进程请求资源 仅当 进程没有资源时；`资源利用率低，可能导致饥饿`
  - 无抢占：如果进程占有某些资源，同时请求其它不能被立即分配的资源，那么就释放当前正占有的资源，将被抢占资源添加到资源列表中，只有当它能够获得旧的资源以及它请求的新的资源，进程才能得到执行；
  - 循环等待：对所有资源类型进行排序，并要求每个进程按照资源顺序进行申请；

- **死锁检测恢复**

  - 死锁检测算法
- 利用抢占恢复
  - 利用回滚恢复
  - 通过杀死进程恢复



**连续内存分配与非连续内存分配对比：**

- 连续内存分配的缺点：
  - 内存的利用率较低；
  - 有外碎片、内碎片的问题
- 非连续分配的优点：
  - 更好的内存利用和管理；
  - 允许共享代码与数据；
  - 支持动态加载与动态链接

**应用程序的逻辑地址是如何映射到物理地址的？**



#### 虚拟内存

每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。虚拟内存让程序可以获得更多的可用内存；（虚拟内存-逻辑地址、物理内存-物理地址）

#### 分段

程序由若干个逻辑分段构成，有代码段、数据段、堆段、栈段。

分段寻址方案：

- 逻辑地址空间分散到多个物理地址空间，逻辑地址由一个二维的二元组构成，分别是段号和段内偏移量；
- 其中段号用作段表的索引，段表里面保存的是这个段的基地址、段的界限和特权等级等；
- 段内偏移量的合法值应该为0至段界限，如果合法，那么物理地址 = 段基地址 + 段内偏移量；

存在的问题：

- 有内存碎片问题：
- 内存交换效率低问题：为了不连续的内存碎片腾位置，需要借助硬盘来实现内存区域的整理，而硬盘的读写速度远远慢于内存，因此效率低下；

#### 分页

分页是把整个逻辑地址空间和物理地址空间切割成一段段固定尺寸的区域，这样一个连续并且尺寸固定的内存空间，称为页，Linux下每页大小4KB；

分页寻址方案：

- 逻辑地址 与 物理地址 之间通过页表来映射；

- 页表 存储在CPU的内存管理单元MMU中，所以CPU可以直接通过MMU找到要实际访问的物理地址；

- 通过页号去找帧号，最后形成物理地址；`页 是连续的虚拟内存，帧 是非连续的物理内存，不是所有的页都有对应的帧`

- 当进程访问的逻辑地址在页表中查不到时，就会产生一个缺页中断，此时会进入系统内核空间分配物理内存，更新进程页表，最后再返回用户空间，恢复进程的运行；

  `逻辑地址分为两部分：页号、页内偏移量，页号是页表的索引，页表中页号对应的是物理页帧的基地址，通过基地址与页内偏移量的组合就可以形成物理内存地址；`

分页解决了分段存在的两个问题：

- 采用分页，每次释放的内存都是以页为单位释放，不会产生无法给进程使用的小内存；
- 分页在内存-硬盘的换入-换出中，一次性写入硬盘的只有少数的页，效率相对较高；同时分页实现了程序运行中，需要用到对应虚拟内存页中的指令和数据时，再加载到物理内存中，进一步提升了效率；

存在的问题：

简单分页可能存在空间上的缺陷，每个进程都会有一个独立的页表，32位环境下，每个页表需要4MB内存来存储，当进程数量非常多时，需要非常多的内存来存储页表；（用多级页表来解决该问题，而多级页表带来的地址转换工序复杂问题，可以由页表缓存TLB来解决，把常访问的几个页表项存储到访问速度更快的硬件，利用MMU完成地址转换和TLB的访问交互，在寻址时，先查TLB，再查常规页表）

#### 页面置换算法

- 最优页面置换算法OPT
- 最近最久未使用LRU
- 最不常用算法LFU
- 最近未使用NRU（时钟页面置换算法Clock）
- 二次机会法ECA（改进时钟算法）
- 先进先出FIFO

#### 段页式



#### 分段与分页的比较









## 3. Linux

#### 常用的linux指令讲一下

- 求助 --help  man  info  doc

- 关机  who  sync  shutdown

- Vim模式：

  - 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容；

    编辑模式（Insert mode）：按下 "i" 等按键之后进入，可以对文本进行编辑；

    指令列模式（Bottom-line mode）：按下`:`按键之后进入，用于保存退出等操作。

    | 命令 | 作用                                                         |
    | ---- | ------------------------------------------------------------ |
    | :w   | 写入磁盘                                                     |
    | :w!  | 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 |
    | :q   | 离开                                                         |
    | :q!  | 强制离开不保存                                               |
    | :wq  | 写入磁盘后离开                                               |
    | :wq! | 强制写入磁盘后离开                                           |

- 文件管理

  - ### 1. ls

    列出文件或者目录的信息，目录的信息就是其中包含的文件。

    ```
    # ls [-aAdfFhilnrRSt] file|dir
    -a ：列出全部的文件
    -d ：仅列出目录本身
    -l ：以长数据串行列出，包含文件的属性与权限等等数据
    ```

    ### 2. cd

    更换当前目录。

    ```
    cd [相对路径或绝对路径]
    ```

    ### 3. mkdir

    创建目录。

    ```
    # mkdir [-mp] 目录名称
    -m ：配置目录权限
    -p ：递归创建目录
    ```

    ### 4. rmdir

    删除目录，目录必须为空。

    ```
    rmdir [-p] 目录名称
    -p ：递归删除目录
    ```

    ### 5. touch

    更新文件时间或者建立新文件。

    ```
    # touch [-acdmt] filename
    -a ： 更新 atime
    -c ： 更新 ctime，若该文件不存在则不建立新文件
    -m ： 更新 mtime
    -d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date="日期或时间"
    -t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm]
    ```

    ### 6. cp

    复制文件。如果源文件有两个以上，则目的文件一定要是目录才行。

    ```
    cp [-adfilprsu] source destination
    -a ：相当于 -dr --preserve=all
    -d ：若来源文件为链接文件，则复制链接文件属性而非文件本身
    -i ：若目标文件已经存在时，在覆盖前会先询问
    -p ：连同文件的属性一起复制过去
    -r ：递归复制
    -u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制
    --preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了
    ```

    ### 7. rm

    删除文件。

    ```
    # rm [-fir] 文件或目录
    -r ：递归删除
    ```

    ### 8. mv

    移动文件。

    ```
    # mv [-fiu] source destination
    # mv [options] source1 source2 source3 .... directory
    -f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖
    ```

- 权限管理

  - ```
    # chmod [ugoa]  [+-=] [rwx] dirname/filename
    - u：拥有者
    - g：所属群组
    - o：其他人
    - a：所有人
    - +：添加权限
    - -：移除权限
    - =：设定权限
    ```

  - 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。

  - 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。

  - ```
    # ln [-sf] source_filename dist_filename
    -s ：默认是实体链接，加 -s 为符号链接
    -f ：如果目标文件存在时，先删除目标文件
    ```

  - 实体链接：

    在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。

    删除任意一个条目，文件还是存在，只要引用数量不为 0。

    有以下限制：不能跨越文件系统、不能对目录进行链接。

  - 符号链接：

    符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。

    当源文件被删除了，链接文件就打不开了。

    因为记录的是路径，所以可以为目录建立符号链接。

- 获取文件内容

  - ### 1. cat

    取得文件内容。

    ```
    # cat [-AbEnTv] filename
    -n ：打印出行号，连同空白行也会有行号，-b 不会
    ```

    ### 2. tac

    是 cat 的反向操作，从最后一行开始打印。

    ### 3. more

    和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。

    ### 4. less

    和 more 类似，但是多了一个向前翻页的功能。

    ### 5. head

    取得文件前几行。

    ```
    # head [-n number] filename
    -n ：后面接数字，代表显示几行的意思
    ```

    ### 6. tail

    是 head 的反向操作，只是取得是后几行。

    ### 7. od

    以字符或者十六进制的形式显示二进制文件。

- 指令与文件搜索

  - ### 1. which

    指令搜索。

    ```
    # which [-a] command
    -a ：将所有指令列出，而不是只列第一个
    ```

    ### 2. whereis

    文件搜索。速度比较快，因为它只搜索几个特定的目录。

    ```
    # whereis [-bmsu] dirname/filename
    ```

    ### 3. locate

    文件搜索。可以用关键字或者正则表达式进行搜索。

    locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。

    ```
    # locate [-ir] keyword
    -r：正则表达式
    ```

    ### 4. find

    文件搜索。可以使用文件的属性和权限进行搜索。

    ```
    # find [basedir] [option]
    example: find . -name "shadow*"
    ```

- 进程管理：

  - ### 1. ps

    查看某个时间点的进程信息。

    示例：查看自己的进程

    ```
    # ps -l
    ```

    示例：查看系统所有进程

    ```
    # ps aux
    ```

    示例：查看特定的进程

    ```
    # ps aux | grep threadx
    ```

    ### 2. pstree

    查看进程树。

    示例：查看所有进程树

    ```
    # pstree -A
    ```

    ### 3. top

    实时显示进程信息。

    示例：两秒钟刷新一次

    ```
    # top -d 2
    ```

    ### 4. netstat

    查看占用端口的进程

    示例：查看特定端口的进程

    ```
    # netstat -anp | grep port
    ```

- 系统管理：

  - top：动态显示进程信息和系统运行统计信息

    free：显示系统运行的统计信息：内存 缓存 缓冲 交换分区；

    ipcs -s/-q/-m：分别显示系统的信号量 消息队列 共享内存

    ipcrm -s/-q/-m id ：根据id 删除信号量 消息队列 共享内存

    lsof：（list open file）：显示系统当前打开的所有文件描述符，所有所有。。。所有

    mpstat：实时监控多处理器系统上每个处理器的使用情况

    vmstat：实时输出系统各个资源的使用情况

- 网络通讯命令:

  - ping：测试网络连通性；

    ifconfig/ip：显示或设置网络设备；

    netstat/ss：显示网络相关信息；

    service：管理系统运行的服务器；

    mail：查看、发送电子邮件；

    write：给用户发信息；

    tcpdump：抓包工具

    nc：快速构建网络连接；

    strace：跟踪程序运行过程中执行的系统调用和接受到的信号，并将系统调用名，参数，返回值以及信号名输出到 标准输出 或者 指定的文件中

    netstat：打印本地网卡接口上的全部连接、路由表信息、网卡接口信息。常用：显示tcp连接以及状态。

- 打包压缩

  - ### 1. gzip

    gzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。

    经过 gzip 压缩过，源文件就不存在了。

    有 9 个不同的压缩等级可以使用。

    可以使用 zcat、zmore、zless 来读取压缩文件的内容。

    ```
    $ gzip [-cdtv#] filename
    -c ：将压缩的数据输出到屏幕上
    -d ：解压缩
    -t ：检验压缩文件是否出错
    -v ：显示压缩比等信息
    -# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6
    ```

    ### 2. bzip2

    提供比 gzip 更高的压缩比。

    查看命令：bzcat、bzmore、bzless、bzgrep。

    ```
    $ bzip2 [-cdkzv#] filename
    -k ：保留源文件
    ```

    压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gzip、bzip2、xz 将打包文件进行压缩。

    ```
    $ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename...  ==打包压缩
    $ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件]              ==查看
    $ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录]    ==解压缩
    -z ：使用 zip；
    -j ：使用 bzip2；
    -J ：使用 xz；
    -c ：新建打包文件；
    -t ：查看打包文件里面有哪些文件；
    -x ：解打包或解压缩的功能；
    -v ：在压缩/解压缩的过程中，显示正在处理的文件名；
    -f : filename：要处理的文件；
    -C 目录 ： 在特定目录解压缩。
    ```

## 4. 设计模式

### 单例模式

#### 饿汉式

```c++
class singleton{
private:
    static singleton *instence = new singleton();
    singleton(); 
public:
    static singleton *getinstence(){
        return instence;
    }
}
```

#### 懒汉式

懒加载：实例对象是第一次被调用的时候才真正的构建，而不是程序启动它就构建好了等着来调用，这种滞后构建的方式就叫做懒加载；懒加载的好处在于，有的对象的构建开销是比较大的，假如这个对象在项目启动时就构建，万一从来就没有调用过，那么就比较浪费了，只有真正需要使用了再去构建，这是更加合理的；

```c++
class singleton{
private: 
    singleton();
    static singleton *instence;
public:
    static singleton *getinstence();
};
//.cpp
singleton* singleton::instence = 0;
singleton* singleton::getinstence(){
    if(instence == NULL){
        instence = new singleton();
    }
    return instence;
}
```

线程安全问题：在构建对象的时候要同步，而在使用对象的时候不需要同步；

```c++
class singleton{
private: 
    singleton();
    ~singleton();
    static singleton *instence;
    singleton(const singleton &m);
    singleton& operator=(const singleton &);
    class a{
    public:
        ~a(){
            if(instence){
                cout<<"a类的析构函数"<<endl;
                delete instence;
            }
        }
    };
    static a aa;
public:
    static singleton *getinstence();
};
singleton::a singleton::aa;
singleton* singleton::instence = NULL;
singleton* singleton::getinstence(){
    if(instence == NULL){
        lock();
        if(instence == NULL)
            instence = new singleton();
        unlock();
    }
    return instence;
}

//不一定对
CRITICAL_SECTION m_sect;
class Lock{
    public:
    Lock(){
        InitializeCriticalSection(&m_sect);
        EnterCriticalSection(&m_sect);
    }
    ~Lock(){
        LeaveCriticalSection(&m_sect);
    }
};
class singleton{
private: 
    singleton();
    ~singleton();
    static singleton *instence;
    singleton(const singleton &m);
    singleton& operator=(const singleton &);
    class a{
    public:
        ~a(){
            if(instence){
                cout<<"a类的析构函数"<<endl;
                delete instence;
            }
        }
    };
    static a aa;
public:
    static singleton *getinstence();
};
singleton::a singleton::aa;
singleton* singleton::instence = NULL;
singleton* singleton::getinstence(){

    if(instence == NULL){
        Lock lock;
        if(instence == NULL)
            instence = new singleton();   
    }
    return instence;
}
```

懒汉双锁式，也存在一定的线程不安全问题，主要原因就在于一个指令重排的问题，首先在`instence = new singleton();`这一句中，new的顺序是先申请变量内存，然后初始化，最后将变量给到instence，但是因为指令重排的原因，可能是先执行3再执行2，这就导致thread1再new的3过程时，thread2进入getinstence（），这时候会出现if判断instence已经存在，就直接返回了instence，而这个instence是未初始化的instence，导致线程的不安全；解决方式是将new这个过程原子化；

#### 局部静态变量式

```c++
class singleton{
private:
    singleton();
    ~singleton();
    singleton(const singleton &instance);
    singleton& operator=(const singleton &instance);
public:
    static singleton& getinstance(){
        static singleton instance;
        return instance;
    }
}
//这种方法又叫做 Meyers' SingletonMeyer's的单例， 是著名的写出《Effective C++》系列书籍的作者 Meyers 提出的。
//所用到的特性是在C++11标准中的Magic Static特性：如果当变量在初始化的时候，并发同时进入声明语句，并发线程将会阻塞等待初始化结束。
//这样保证了并发线程在获取静态局部变量的时候一定是初始化过的，所以具有线程安全性。
//C++11以后,规定了local static在多线程条件下的初始化行为，要求编译器保证了内部静态变量的线程安全性.
//也就是说local static变量会在编译期初始化,我们可以利用这一特性完成单例.
```

**局部静态变量**

> 函数内声明的静态变量为函数内的static对象，在函数第一次被调用时初始化。编译器会保证在进程退出前析构函数会被调用。静态函数实现，则在程序退出时会调用静态函数的析构方法，只要是静态实例，在程序退出后会调用析构函数。
>
> 如果是New出来的实例，而没有显式调用析构函数，在程序退出时并不会调用析构函数。因此，如果单例模式以此方式实现，则会产生泄露（像数据库连接、OS内核对像，网络连接等可能不会被正确关闭）；

关于为什么成员属性与成员变量都必须式静态的：

使用类中方法只有两种方式，①创建类的一个对象，用对象去调用方法；②使用类名直接调用类中方法。
显然第一种情况不能用，只能使用第二种方法。而想要使用类名直接调用类中方法，类中方法必须是静态的，而静态方法不能访问非静态成员变量，因此类自定义的实例变量也必须是静态的。这就是为什么单例模式的唯一实例为什么设置为静态的。



## 5. 数据库



#### Redis的5大结构



#### Redis 的 zset 的底层数据结构



#### Redis 实现分布式锁



#### 数据库索引



#### B与B+的区别，B+树高度低带来的好处是啥



## 6. C11

#### 左值右值的区别



#### 智能指针

智能指针类将一个计数器与类指向的对象相关联，引用计数跟踪该类有多少个对象共享同一指针。每次创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数；对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。智能指针就是模拟指针动作的类。所有的智能指针都会重载 -> 和 * 操作符。智能指针还有许多其他功能，比较有用的是自动销毁。这主要是利用栈对象的有限作用域以及临时对象（有限作用域实现）析构函数释放内存。

- 智能指针的设计思想
- 为什么摒弃auto_ptr
- unique_ptr为什么优于auto_ptr
- 如何选择只能指针

#### 完美转发



#### C++ 4种cast 区别和主要使用场景

1. **const_cast**：用于将const转换为非const；
2. **static_cast**：用于各种**隐式转换**，比如非const转换为const。 void*转指针等。用于多态向上转化，向下转化成功但不安全，结果未知；
3. **dynamic_cast**：用于**动态类型转换**，只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的，对于指针返回NULL；对于引用抛异常，要深入了解内部转换的原理。向上转换：指的是子类向基类的转换；向下转换：指的是基类向子类的转换；它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。
4. **reinterpret_cast**：几乎什么都可以转，**比如int转指针，可能会出现问题**。尽量少用；
5. **为什么不使用C的强制转换**：C的强制转换，表面上看起来功能强大。但是不能进行错误检查，易出错。

其中，**dynamic_cast**这种其实也是**不被推荐使用的**，**更多使用static_cast**，dynamic**本身只能用于存在虚函数的父子关系的强制类型转换**，对于指针，转换失败则返回nullptr，对于引用，转换失败会抛出异常。

## 7. 网络编程

#### select \ poll \ epoll 的区别？

这三个都是IO复用的具体实现，其中select出现的最早，然后是poll，最后是epoll；

select：允许应用程序来监视一组文件描述符，等待一个或者多个文件描述符成为就绪状态，从而完成IO操作；

poll：poll的功能与select是类似的，也是等待一组文件描述符中的一个成为就绪状态；

epoll：epoll是Linux内核为处理大量句柄而改进的poll，是linux特有的I/O函数；epoll有两种工作方式，LT水平触发 、ET边沿触发。LT是select/poll的工作方式，比较低效，而ET是epoll具有的高速工作方式。

select与poll的区别：

- select 会修改描述符，而 poll 不会；
- select 的描述符类型使用数组实现，`FD_SETSIZE`大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 `FD_SETSIZE`之后重新编译；而 poll 没有描述符数量的限制；
- poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
- 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。
- select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。
- 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。

epoll对select与poll的区别：

- epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。
- epoll 仅适用于 Linux OS。
- epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。
- epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。

应用场景：

- select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景；
- poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
- 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接，可以用epoll；

不用epoll的地方：

- 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。
- 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。

#### epoll模型的工作原理



#### IO多路复用与多进程

如果压力不是很大，并且处理性能相对于IO可以忽略不计

- IO多路复用+单进（线）程比较省资源
- 适合处理大量的闲置的IO
- IO多路复用+多单进（线）程与线程池方案相比有好处，但是并不会有太大的优势

如果压力很大，什么方案都得跪，这时就得扩容。当然因为IO多路复用+单进（线）程比较省资源，所以扩容时能省钱。

#### 多进程和多线程



#### IO模型

有五种IO模型：阻塞IO、非阻塞IO、异步IO、IO复用、信号驱动IO；

阻塞IO：

非阻塞IO：

信号驱动IO：

异步IO：

#### 线程池？线程池用过没，需要注意哪些事项

> 这里主要是考察大家对于各种连接池的理解。提前创建一定数量的连接，需要的时候直接使用即可，不用每次频繁的创建连接。常用的连接池有redis连接池，HTTP连接池等。这里会涉及到最大的连接数和最小的连接数。那么连接数的大小一般怎么控制？

- 当前连接数小于最小连接数，那么就创建连接
- 如果连接池有空闲则复用
- 如果此时当前连接数大于最大连接数，考虑设置超市等待，异常处理

线程池主要用于：

1）需要大量的线程来完成任务，且完成任务的时间比较短。 比如WEB服务器完成网页请求这样的任务，使用线程池技术是非常合适的。因为单个任务小，而任务数量巨大。但对于长时间的任务，比如一个Telnet连接请求，线程池的优点就不明显了。因为Telnet会话时间比线程的创建时间大多了。

2）对性能要求苛刻的应用，比如要求服务器迅速响应客户请求。

3）接受突发性的大量请求，但不至于使服务器因此产生大量线程的应用。

#### socket的流程

先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。

![img](https://upload-images.jianshu.io/upload_images/14479440-913393a6f4c24564.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/478/format/webp)

- 这个connect（）与accept（）的过程其实就是TCP三次握手的过程；

```c++
//socket建立TCP连接-服务器端
/*
1.socket()创建TCP套接字                                                                              
2.bind()将创建的套接字绑定到一个本地地址和端口上                                        
3.listen()，将套接字设为监听模式，准备接受客户请求                                        
4.accept()等用户请求到来时接受，返回一个对应此连接新套接字   
5.用accept()返回的套接字和客户端进行通信，recv()/send() 接受/发送信息。                               
6.返回，等待另一个客户请求。
7.关闭套接字
*/
//socket建立TCP连接-客户端
/*
1.socket()创建TCP套接字。
2.connect()建立到达服务器的连接。
3.与客户端进行通信，recv()/send()接受/发送信息，write()/read() 子进程写入管道，父进程从管道中读取信息然后send给客户端。
4. close() 关闭客户连接。
*/ 
```

#### 如果socket出现问题，你如何定位到这个错误呢？

一般用侦听软件可以捕获错误，例如: Fiddler

#### Socket是什么？Socket属于网络的哪一层？

socket是应用层与传输层的一个抽象，将复杂的TCP/IP协议隐藏在Socket接口之后，只对应用层暴露简单的接口，以实现进程在网络中通信；

socket是一种特殊的文件，它也有文件描述符，进程可以打开一个socket，并且像处理文件一样对它进行read()和write()操作，而不必关心数据是怎么在网络上传输的

socket是一个tcp连接的两端

#### Socket如何唯一标识一个进程？

socket基于tcp协议实现，网络层的**ip地址**唯一标识一台主机，而**传输层的协议+端口号**可以唯一标识绑定到这个端口的进程；

#### 通信双方如何进行端口绑定？

通常服务端启动时会绑定一个端口提供服务，而客户端在发起连接请求时会被随机分配一个端口号

#### Socket是全双工的吗？

基于TCP协议，是全双工的

#### HTTP协议是全双工的吗？

HTTP 协议设计的初衷本身就是请求/响应模式，这是规范决定的，也就是单工模式通信，但是在技术上是可以利用下层的 TCP 来进行全双工通信的。

## 8. C++

#### malloc和new的区别

- malloc与free成对使用，new与delete成对使用，malloc是函数，而new是操作符重载；

- **申请的内存所在位置**：**new**操作符从自由存储区上为对象动态分配内存，而malloc函数从堆上动态分配内存。自由存储区是C++ 基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区是否能够是堆（问题等价于new是否能在堆上动态分配内存），这取决于operator new 的实现细节。自由存储区不仅可以是堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。

- **返回类型安全性**：new操作符分配内存成功时，返回的对象类型是指针，类型与对象严格匹配，无需进行类型转换，即安全；而malloc内存分配成功则是返回void*，需要通过强制类型转换成所需类型。

- **内存分配失败时的返回值**：new内存分配失败时，会抛出bad_alloc异常，不会返回NULL；malloc分配内存失败时返回NULL。

- **是否需要指定内存大小**：使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息进行自行计算，而malloc则要显示地指出所需内存的尺寸

- **是否调用构造函数/析构函数**：**使用new操作符来分配对象内存时会经历三个步骤**：

  - 第一步：调用operator new 函数（对于数组是operator new[]）分配一块足够大的，原始的，未命名的内存空间以便存储特定类型的对象。

  - 第二步：编译器运行相应的构造函数以构造对象，并为其传入初值。

  - 第三步：对象构造完成后，返回一个指向该对象的指针。 

    **使用delete操作符来释放对象内存时会经历两个步骤**：

  - 第一步：调用对象的析构函数。

  - 第二步：编译器调用operator delete(或operator delete[])函数释放内存空间。 总之来说，new/delete会调用对象的构造函数/析构函数以完成对象的构造/析构。

- **对数组的处理**：C++提供了new[]与delete[]来专门处理数组类型。使用new[]分配的内存必须使用delete[]进行释放。new对数组的支持体现在它会分别调用构造函数函数初始化每一个数组元素，释放对象时为每个对象调用析构函数。注意delete[]要与new[]配套使用，不然会找出数组对象部分释放的现象，造成内存泄漏。

- **new与malloc是否可以相互调用**：operator new /operator delete的实现可以基于malloc，而malloc的实现不可以去调用new。new可以被重载；

- **能够直观地重新分配内存**：**使用malloc分配的内存后，如果在使用过程中发现内存不足，可以使用realloc函数进行内存重新分配实现内存的扩充**。realloc先判断当前的指针所指内存是否有足够的连续空间，如果有，原地扩大可分配的内存地址，并且返回原来的地址指针；如果空间不够，先按照新指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来的内存区域。new没有这样直观的配套设施来扩充内存

- **客户处理内存分配不足**：**在operator new抛出异常以反映一个未获得满足的需求之前，它会先调用一个用户指定的错误处理函数，这就是new-handler**。对于malloc，客户并不能够去编程决定内存不足以分配时要干什么事，只能看着malloc返回NULL。

#### 构造函数和、析构函数能不能是虚函数

构造函数不可以是虚函数：虚函数的调用是需要虚函数表指针的，指针指向对应虚函数的地址，而指针是存放在对象的内存空间中的，如果构造函数声明为虚函数，那么因为对象还没有创建，没有对象的内存空间，也就没办法用虚函数表来调用虚构造函数了；

析构函数可以是虚函数：在使用基类指针或引用调用子类的时候，最好将基类的析构函数定义为虚析构函数，否则可能导致内存泄漏的问题；主要是在父类指针指向子类对象的时候，如果释放了父类指针，这时只会调用父类的析构函数，释放掉了子类中的父类部分，而派生类部分是没有被析构掉的，造成内存泄漏；

*这份信息通常是由一个所谓 vptr（virtual table pointer —— 虚函数表指针）指针指出。vptr 指向一个由函数指针构成的数组，称为 vtbl（virtual table —— 虚函数表）；每一个带有 virtual 函数的类都有一个相应的 vtbl。当对象调用某一 virtual 函数，实际被调用的函数取决于该对象的 vptr 所指向的那个 vtbl，接着编译器在其中寻找适当的函数指针，从而调用对应类的函数。*

#### 模板与继承的对比，模板的缺点，模板是如何编译的*

模板默认内联，且没有虚表指针，调用开销小 ；

编译慢、编译产物更占用内存 ；

编译期碰到了就生成需要的代码，每个.o都会有用到的定义，所以链接的时候要去掉重定义，因此编的慢；

#### 智能指针-STL四种（细、手写智能指针）

智能指针：智能指针其实就是一个类，指针对象离开作用域之后会自动调用析构函数，释放内存，防止出现内存泄漏的问题；智能指针主要用于**管理在堆上分配的内存**，它**将普通的指针封装为一个栈对象**。当栈对象的生存周期结束后，会在析构函数中释放掉申请的内存，从而防止内存泄漏。C++ 11中**最常用的智能指针类型为shared_ptr**,它采用引用计数的方法，记录当前内存资源被多少个智能指针引用。**该引用计数的内存在堆上分配**。当新增一个时引用计数加1，当过期时引用计数减一。只有引用计数为0时，智能指针才会自动释放引用的内存资源。对shared_ptr进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类。可以通过**make_shared函数或者通过构造函数传入普通指针。并可以通过get函数获得普通指针**。

**auto_ptr** - 采用所有权模式

c11建议弃用，主要原因就是auto指针是唯一拥有者模型，也就是在通过拷贝构造函数或者赋值运算符进行操作之后，资源的唯一拥有者将变为新的指针对象，而原来的指针对象变为了null，所以如果不小心再次使用了原指针，则必然会导致程序的崩溃；

**unique_ptr**-**独占式拥有或严格拥有**

unique指针也是唯一拥有者模型，它相比于auto指针，直接禁止了通过拷贝构造或者赋值操作符的copy行为，但是可以通过move函数实现资源所有权的转移，就是从一个unique指针转移到另一个unique指针，旧的unique指针不在拥有资源的所有权；

**当程序试图将一个unique_ptr赋值给另一个时，如果源unique_ptr是一个临时右值，则可以这么做；如果源unique_ptr已存在一段时间，则不可。**

```c++
unique_ptr<string> p1(new string ("hello world"));
unique_ptr<string> p2;
p2 = p1;// !1 not allowed
unique_ptr<string> p3;
p3 = unique_ptr<string> (new string ("You"));// !2 allowed
//调用 unique_ptr 的构造函数，该构造函数创建的临时对象在其所有权让给 p3 后就会被销毁
```

```c++
//构造 unique_ptr
std::unique_ptr<Entity> e1(new Entity);     //ok
std::unique_ptr<Entity> e1 = std::make_unique<Entity>();   // preferred
auto e1 = std::make_unique<Entity>();   //preferred
//移动 unique_ptr
std::unique_ptr<Entity> e2 = std::move(e1);
func(move(e1));
```

**shared_ptr**-**共享式拥有**

shared指针是共享的拥有者模型，加入了引用计数机制；多个智能指针可以指向相同对象，该对象和其他相关资源会在**“最后一个引用被销毁”**时释放。使用**计数**机制来表明资源被几个指针共享。可以通过**成员函数use_count()查看资源的所有者个数**。除了可以通过new来构造，还可以通过传入auto_ptr, unique_ptr,weak_ptr来构造。当我们**调用release()**时，当前指针会释放资源所有权，计数减一。**当计数等于0时，资源会被释放**。

shared_ptr 是为了解决 auto_ptr 在对象所有权上的局限性(auto_ptr 是独占的), 在使用引用计数的机制上提供了可以共享所有权的智能指针。

**成员函数**：

use_count 返回引用计数的个数

unique 返回是否是独占所有权( use_count 为 1)

swap 交换两个 shared_ptr 对象(即交换所拥有的对象)

reset 放弃内部对象的所有权或拥有对象的变更, 会引起原有对象的引用计数的减少

get 返回内部对象(指针), 由于已经重载了()方法, 因此和直接使用对象是一样的.如 shared_ptr<int> sp(new int(1)); sp 与 sp.get()是等价的

**weekly_ptr**

weak_ptr是一种**不控制对象生命周期的智能指针**, 它**指向一个 shared_ptr 管理的对象**。 进行该对象的内存管理的是那个强引用的shared_ptr。weak_ptr只是提供了对管理对象的一个访问手段。weak_ptr设计的目的是为配合shared_ptr而引入的一种智能指针来协助shared_ptr工作，它只可以从一个shared_ptr或另一个weak_ptr对象构造，它的构造和析构不会引起引用记数的增加或减少。**weak_ptr是用来解决shared_ptr相互引用时的死锁问题**,如果说两个shared_ptr相互引用,那么这两个指针的引用计数永远不可能下降为0,资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和shared_ptr之间可以相互转化，shared_ptr可以直接赋值给它，它可以通过调用lock函数来获得shared_ptr。

注意的是我们**不能通过weak_ptr直接访问对象的方法**，比如B对象中有一个方法print(),我们不能这样访问，pa->pb_->print(); pb_是一个weak_ptr，应该先把它转化为shared_ptr,如：shared_ptr p = pa->pb_.lock(); p->print();

#### 浅拷贝与深拷贝



#### 一个类A，里面有两个整型变量，一个成员函数，两个虚函数，问这个类占多大内存



#### 空悬指针与野指针？怎么避免空悬指针？



#### NULL与nullptr差别



#### 虚函数以及虚函数表指针、虚函数表原理



#### .cpp与.c编译时的区别



#### 数组和链表的区别



#### 重载与重写



#### C++ 的内存管理是怎么实现的



#### 指针和引用的区别？

1. **指针有自己的一块空间**，而**引用只是别名**；
2. 使用**sizeof看一个指针的大小是4**，而**引用则是被引用对象的大小**；
3. **指针可以被初始化为NULL**，而引用必须被初始化且必须是一个已有对象的引用；
4. 作为参数传递时，**指针需要被解引用才可以对对象进行操作**，而直接对引用的修改都会引用所指向的对象；
5. 可以**有const指针**，但是没有const引用；
6. **指针在使用时可以指向其他对象**，但引用只能是一个对象的引用，不能被改变；
7. **指针可以有多级指针**，但是不能有多级引用；
8. **指针和引用的++含义不一样**；
9. 返回**动态内存分配的对象只能是指针**，**引用可能会导致内存泄漏**。

为什么传指针比传引用安全？

#### strlen和sizeof





#### 时间复杂度，如果一个算法的时间复杂度是O(1)代表的含义是什么



#### 头文件重复的包含和重复的引用



#### struct与union有什么区别？ 



#### 堆和栈有啥区别

主要的区别由以下几点：

1、管理方式不同；

2、空间大小不同；

3、能否产生碎片不同；

4、生长方向不同；

5、分配方式不同；

6、分配效率不同；

管理方式：对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。

空间大小：一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的，例如，在VC6下面，默认的栈空间大小是1M（好像是，记不清楚了）。当然，我们可以修改：

碎片问题：对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的队列，他们是如此的一一对应，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出，

生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。

分配方式：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。

分配效率：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。

#### struct内存对齐原则有哪些？

为什么要内存对齐：比如在一个32为操作系统中，数据总线是32位的，意味着读取一次就可以读出4个字节，那如果没有内存对齐，可能一个4字节的数据变量需要用两次IO操作才能够读取出来，而IO操作是非常耗时的，所以利用内存对齐原则可以减少IO操作的次数，减少系统的开销；

1、没有#pragma pack宏的对齐规则

- 1.结构体的起始存储位置必须是能够被该结构体中最大的数据类型所整除。
- 2.每个数据成员存储的起始位置是自身大小的整数倍(比如int在32位机为4字节，则int型成员要从4的整数倍地址开始存储)。
- 3.结构体总大小（也就是sizeof的结果），必须是该结构体成员中最大的对齐模数的整数倍。若不满足，会根据需要自动填充空缺的字节。
- 4.结构体包含另一个结构体成员，则被包含的结构体成员要从其原始结构体内部最大对齐模数的整数倍地址开始存储。(比如struct a里存有struct b，b里有char,int,double等元素,那b应该从8的整数倍开始存储。)
- 5.结构体包含数组成员，比如char a[3],它的对齐方式和分别写3个char是一样的，也就是说它还是按一个字节对齐。如果写：typedef char Array[3],Array这种类型的对齐方式还是按一个字节对齐，而不是按它的长度3对齐。
- 6.结构体包含共用体成员，则该共用体成员要从其原始共用体内部最大对齐模数的整数倍地址开始存储。

2、存在#pragma pack宏的对齐

```c++
#pragma pack (n)    //编译器将按照n个字节对齐  
#pragma pack ()     //取消自定义字节对齐方式
```

那么对齐规则就变成下面的

- 结构，联合，或者类的数据成员，第一个放在偏移为0的地方，以后每个数据成员的对齐，按照#pragma pack指定的数值和自身对齐模数中较小的那个。

#### inline关键字有什么作用？ 

- inline是C语言中的一个关键字，可以用于程序中定义内联函数，inline的引进使内联函数的定义更加简单。说到内联函数，这里给出比较常见的定义，==内联函数是C中的一种特殊函数，它可以像普通函数一样被调用，但是在调用时并不通过函数调用的机制而是通过将函数体直接插入调用处来实现的，这样可以大大减少由函数调用带来的开销，从而提高程序的运行效率==。一般来说inline用于定义类的成员函数。

- ```c++
  inline 返回值类型  函数名（函数参数）{
      //定义函数体
  }
  inline int sum (int a,int b){
      return a+b;
  }
  ```

一般来说，inline适用的函数有两种，

1. 一种是在类内定义的成员函数；这种情况下，**我们可以不用在函数头部加inline关键字**，因为编译器会自动将类内定义的函数声明为内联函数;
2. 另一种是在类内声明，类外定义的成员函数。根据C++编译器的规则，这种情况下如果想将该函数设置为内联函数，则可以在类内声明时不加inline关键字，而在类外定义函数时加上inline关键字;

#### 内联函数与宏定义的区别？(inline函数与define?)

- **内联函数的优点**：

  - inline 定义的类的内联函数，函数的代码被放入符号表中，在使用时直接进行替换，（像宏一样展开），没有了调用的开销，效率也很高。
  - 很明显，类的内联函数也是一个真正的函数，编译器在调用一个内联函数时，会首先检查它的参数的类型，保证调用正确。然后进行一系列的相关检查，就像对待任何一个真正的函数一样。这样就消除了它的隐患和局限性。（宏替换不会检查参数类型，安全隐患较大）
  - inline函数可以作为一个类的成员函数，与类的普通成员函数作用相同，可以访问一个类的私有成员和保护成员。内联函数可以用于替代一般的宏定义，最重要的应用在于类的存取函数的定义上面。

- **内联函数的优点**：

  - 内联函数具有一定的局限性，内联函数的函数体一般来说不能太大，如果内联函数的函数体过大，一般的编译器会放弃内联方式，而采用普通的方式调用函数。(换句话说就是，你使用内联函数，只不过是向编译器提出一个申请，编译器可以拒绝你的申请）这样，内联函数就和普通函数执行效率一样了；
  - inline说明对编译器来说只是一种建议，编译器可以选择忽略这个建议。比如，你将一个长达1000多行的函数指定为inline，编译器就会忽略这个inline，将这个函数还原成普通函数，因此并不是说把一个函数定义为inline函数就一定会被编译器识别为内联函数，具体取决于编译器的实现和函数体的大小。

- **注意事项**

  - 内联函数不能包括复杂的控制语句，如循环语句和switch语句；
  - 只将规模很小（一般5个语句一下）而使用频繁的函数声明为内联函数。在函数规模很小的情况下，函数调用的时间开销可能相当于甚至超过执行函数本身的时间，把它定义为内联函数，可大大减少程序运行时间。

- **宏定义**：预处理命令可以改变程序设计环境,提高编程效率,它们并不是 C 语言本身的组成部分,不能直接对 它们进行编译,必须在对程序进行编译之前,先对程序中这些特殊的命令进行“预处理” 。经过预处理后,程序就不再包括预处理命令了,最后再由编译程序对预处理之后的源程序进行编译处理,得到可供执行的目标代码。C 语言提供的预处理功能有三种,分别为**宏定义、文件包含和条件编译**。

  C 语言源程序中允许用一个标识符来表示一个字符串,称为“宏/宏体” ,被定义为“宏”的标识符称为“宏名”。在编译预处理时,对程序中所有出现的宏名,都用宏定义中的字符串去代换,这称为“宏替换”或“宏展开”。 宏定义是由源程序中的宏定义命令完成的,宏代换是由预处理程序自动完成的。

- **宏定义优点**：

  - 方便程序的修改：使用简单宏定义可用宏代替一个在程序中经常使用的常量，这样在将该常量改变时，不用对整个程序进行修改，只修改宏定义的字符串即可
  - 提高运行效率：

- **宏定义缺点**：

  - 由于是直接嵌入的，所以代码可能相对多一点；
  - 嵌套定义过多可能会影响程序的可读性，而且很容易出错，不容易调试；
  - 对带参的宏而言，由于是直接替换，并不会检查参数是否合法，存在安全隐患

- **内联函数和宏定义的区别**：

  - **宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的**。而且**内联函数是真正的函数，只是在需要用到的时候，内联函数像宏一样的展开，所以取消了函数的参数压栈，减少了调用的开销**。你可以象调用函数一样来调用内联函数，而不必担心会产生于处理宏的一些问题。内联函数与带参数的宏定义进行下比较，它们的代码效率是一样，但是内联欢函数要优于宏定义，因为内联函数遵循的类型和作用域规则，它与一般函数更相近，在一些编译器中，一旦关联上内联扩展，将与一般函数一样进行调用，比较方便。

    另外，宏定义在使用时只是简单的文本替换，并没有做严格的参数检查，也就不能享受C++编译器严格类型检查的好处，另外它的返回值也不能被强制转换为可转换的合适的类型，这样，它的使用就存在着一系列的隐患和局限性。

    C++的inline的提出就是为了完全取代宏定义，因为inline函数取消了宏定义的缺点，又很好地继承了宏定义的优点

#### 什么是内存泄漏？如何避免？

<u>为什么会存在内存泄漏问题？</u>

通常来说，一个线程的栈内存是有限的，通常来说是 8M 左右（取决于运行的环境）。栈上的内存通常是由编译器来自动管理的。当在栈上分配一个新的变量时，或进入一个函数时，栈的指针会下移，相当于在栈上分配了一块内存。我们把一个变量分配在栈上，也就是利用了栈上的内存空间。当这个变量的生命周期结束时，栈的指针会上移，相同于回收了内存。由于栈上的内存的分配和回收都是由编译器控制的，所以在栈上是不会发生内存泄露的，只会发生栈溢出（Stack Overflow），也就是分配的空间超过了规定的栈大小。

内存泄漏的分类：

- **堆内存泄漏 （Heap leak）**。堆内存指的是程序运行中根据需要分配通过**malloc,realloc new**等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。
- **系统资源泄露（Resource Leak）**。主要指程序**使用系统分配的资源**比如 Bitmap,handle ,SOCKET等**没有使用相应的函数释放掉**，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
- **没有将基类的析构函数定义为虚函数**。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

内存溢出(out of memory)：程序在申请内存时，没有足够的内存空间供其使用。原因可能如下：

- 内存中加载的数据过于庞大；
- 代码中存在死循环；
- 递归调用太深，导致堆栈溢出等；
- 内存泄漏最终导致内存溢出；

<u>避免方法：</u>

- 尽量使用`智能指针`，而不是手动地去管理内存
- 使用 std::string 来替代 char*。使用 std::string 无需关心内存管理，它已经很好地在内部实现了内存管理。
- 无论如何都不要使用一个裸指针，除非逼不得已（比如要用它来指向一个旧的库）
- 在 C++ 中最好的避免内存泄漏的方式是尽量少的使用 new 和 delete 函数，最好是0使用。当你确实需要动态内存的时候，构造一个 RAII 类来在析构的时候自动地 delete 所有动态申请的内存。 RAII 类在构造函数中申请内存，而在析构函数释放内存，所以这可以保证在 RAII 对象离开作用域的时候，自动地释放内存。
- 在你每次确实需要申请动态内存的时候，先写 new 和 delete 语句。然后再在中间添加你的功能模块！这样做确保你不会忘记释放内存！

#### strcpy和memcpy的区别？



#### const关键字

- 修饰变量：说明这个变量是不可以被改变的；

- 修饰指针：分为指针常量、常量指针、指向常量的常指针；

  ```c++
  //常量指针-指向常量的指针；
  const int *ptr;
  //指针常量-指针变量指向的空间地址是常量；
  int * const ptr;
  //指向常量的常指针-指针指向的地址空间和该地址空间存放的内容都是不可以修改的；
  const int * const ptr;
  ```

- 修饰引用：经常用于形参类型，既避免了拷贝`(拷贝构造一个临时对象，类似于值传递，徒增开销)`，又避免了函数对值的修改

- 修饰成员函数：说明该成员函数内不能修改成员变量，本质是 const this 指针,常量成员函数不能调用一般成员函数，也不能修改一般成员变量的值；

#### static关键字

1. **全局静态变量**

- 在全局变量之前加上关键字static
- 存储在静态存储区，在整个程序运行期间一直存在
- 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非被他显示初始化）
- 作用域：全局静态变量在声明他的文件之外是不可见的。

1. **局部静态变量**

- 局部变量之前加上关键字static
- 存储在静态存储区
- 初始化：未经初始化的局部静态变量会被自动初始化为0
- 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束是，作用域结束。但是并没有被销毁，仍保留在内存中，直到函数再次被调用，值不变。

1. **静态函数**

- 在函数返回类型之前加static。函数的定义和声明默认情况下都是extern的，但是静态函数只是在声明他的文件中可见的，不能被其他文件所用。
- 函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突。
- warning：不要在头文件中声明static的全局函数，不要在cpp内声明非static的全局函数。如果在多个cpp中复用该函数，就将其声明提到头文件，否则cpp内部声明需加上static。

1. **类的静态成员**

- 在类中，静态成员可以实现多个对象之间的数据共享，并且使用静态成员不会破坏隐藏的原则，保证了安全性。因此，静态成员是类的所有对象中共享的成员，而**不是某个对象的成员**。

1. **类的静态函数**

- 静态成员函数和静态数据成员一样，它们都属于类的静态成员，它们都不是对象成员。因此，对静态成员的引用不需要用对象名。在静态成员函数的实现中不能直接引用类中说明的**非静态成员**，可以引用类中说明的静态成员（这点非常重要）。如果静态成员函数中要**引用非静态成员时**，可通过对象来引用。从中可看出，**调用静态成员函数**使用如下格式：<类名>::<静态成员函数名>(<参数表>);//::表示作用域

对于函数定义和代码块之外的变量声明，static修改标识符的链接属性。由默认的extern变为intern，作用域和存储类型不变，这些符号只能在声明他的源文件中访问。

#### extern关键字

extern关键字主要修饰变量或函数，表示该函数可以跨文件访问，或者表明该变量在其他文件定义，在此处引用。

- **修饰变量或函数**：被 extern 限定的函数或变量是 extern 类型的，如在头文件中: extern int g_Int; 它的作用就是声明函数或全局变量的作用范围的关键字，其声明的函数和变量可以在本模块和其他模块中使用，记住它是一个声明不是定义!也就是说B模块(编译单元)要是引用模块(编译单元)A中定义的全局变量或函数时，它只要包含A模块的头文件即可,在编译阶段，模块B虽然找不到该函数或变量，但它不会报错，它会在连接时从模块A生成的目标代码中找到此函数。
- extern "C" 的作用是让 C++ 编译器将 extern "C" 声明的代码当作 C 语言代码处理，可以避免 C++ 因符号修饰导致代码不能和C语言库中的符号进行链接的问题。当它与"C"一起连用时，如: extern "C" void fun(int a, int b);则告诉编译器在编译fun这个函数名时按着C的规则去翻译相应的函数名而不是C++的
  - 在c头文件中通过#ifdef __cplusplus extern "C" { #endif来定义
  - 在对应的c文件中实现
  - 在cpp文件中通过“extern "C" 函数名”调用，或者包含c头文件 **注意**： extern的引用方式比包含头文件要简洁得多！extern的使用方法是直接了当的，想引用哪个函数就用extern声明哪个函数。这样做的一个明显的好处是，会加速程序的编译（确切的说是预处理）的过程，节省时间，但若需要调用的函数太多，还是直接包含头文件吧。

**volatile关键字**

- **不可优化性**. volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。
- **易变性**. volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值）

#### 为什么引入抽象基类和纯虚函数？



#### 



#### 虚函数和纯虚函数有什么区别



#### 构造函数与析构函数的调用顺序是怎样的



#### 多态与底层

多态是c++面向对象的三大特性之一，

虚函数：在类的成员函数前加上virtual关键字，就构成了虚函数；

多态的底层是利用**虚函数表**来实现的；虚函数表是通过一块连续内存来存储虚函数的地址，这张表解决了继承，虚函数（重写）的问题，在有虚函数的对象实例中都存在一张虚函数表，虚函数表就像一张地图，指明了实际应该调用的虚函数。虚表中依次存储了各个虚函数的地址，且存放的顺序和代码中定义的虚函数的顺序一致。当进行多态调用时，编译器根据传入对象的类别，找到对应的vfptr（虚表指针），再查看你要调用的函数在类中定义的位置，来找到该虚函数在虚表中存储的位置，实现调用。

#### c++中map底层实现，红黑树说一下

红黑树形式的存储的键值是有序的，同时红黑树的插入，删除可以在O(logn)的完成。

红黑树的性质

- 红黑树的每个节点要么是红色要么是黑色
- 红黑树的根节点一定是黑色
- 红黑树的所有外部节点都是黑色
- 红黑树的所有有红色节点的两个子节点一定是黑色节点
- 红黑树从根到任意一个外部节点的路径上的黑色节点的数目相同

说到map，也说说hashmap和Treemap。

C++中unordered_map的底层是用哈希表来实现的，通过key的哈希路由到每一个桶（即数组）用来存放内容。通过key来获取value的时间复杂度就是O（1）。因为key的哈希容易碰撞，所以需要对碰撞做处理。unordered_map里的每一个数组（桶）里面存的其实是一个链表，key的哈希冲突以后会加到链表的尾部，这是再通过key获取value的时间复杂度就变成O(n），当碰撞很多的时候查询就会变慢。为了优化这个时间复杂度，map的底层就把这个链表转换成了红黑树，这样虽然插入增加了复杂度，但提高了频繁哈希碰撞时的查询效率，使查询效率变成O(log n)。

#### HashMap的底层实现；HashMap是否是线程安全的



####  



#### STL库与底层的实现；





#### define和const的区别？



#### 仿函数与指针函数有啥区别？



#### unordered_map 和map区别



#### 递归层数太多会怎么样，为什么



#### typedef



#### 什么是面向对象编程？什么是面向过程编程？



## 9. 其他

#### 软件工程常用开发模型？ 软件开发流程 



#### Utf-8几个字节，汉字呢？



#### Memory load



#### move，forward



#### 动态链接库原理？静态链接库跟动态链接库异同比较？动态链接库实际存了哪些东西? 怎么引用动态链接库，什么是动态库、静态库？



#### gdb常用命令有什么



#### 哈希冲突有哪些解决方法



#### LRU如何实现的

\1. 如果内存只有10G，搜索引擎得到的数据有100T，按数据频度排序

\2. 三次握手四次挥手

\3. LRU 算法(进阶: 多线程访问LRU/ 流数据刷LRU)









## 10 手撕算法

### 链表

#### 建立一个双向链表；

```c++
//
```

#### 设计一个数据结构 list:  rpush rpop lpush lpop index 五种方法的时间复杂度均为 O(1)



#### 反转链表

```c++
//递归法
struct ListNode{
    int val;
    ListNode *next;
    ListNode(int x) : val(x),next(NULL) {}
};
class solution{
public:
    ListNode * reverseList(ListNode *head){
        if(head == NULL || head->next == NULL) return head;
        ListNode * last = reverseList(head->next);
        head->next->next = head;
        head->next = NULL;
        return last;        
    }
};
//迭代法
class solution{
public:
    ListNode * reverseList(ListNode *head){
        if(head == NULL) return NULL;
        ListNode * pre = NULL;
        ListNode * cur = head;
        while(cur != NULL){
            ListNode * temp = cur->next;
            cur->next = pre;
            pre = cur;
            cur = temp;
        }
        return pre;
    }
}
```

#### leetcode 92 反转链表从m到n

```c++
//迭代法
struct ListNode{
    int val;
    ListNode * next;
    ListNode(int x) : val(x),next(NULL) {}
}
class solution{
public:
    ListNode * reverse(ListNode *head, int m, int n){
        if(m == 1){
            ListNode *ptr = reverseN(head,n);
            return ptr;
        }
        ListNode *last = reverse(head->next,m-1,n-1);
        head->next = last;
        return head;
    }
    ListNode * reverseN(ListNode *head, int n){
        if(n == 1){
            successed = head->next;
            return head;
        }
        ListNode *last = reverseN(head->next,n-1);
        head->next->next = head;
        head->next = successed;
        return last;
    }
    ListNode *successed;
};
```

#### leetcode 25 K个一组反转链表；



#### 判断链表是否有环,并返回入环节点

```c++
//
/**
 * Definition for singly-linked list.
 * struct ListNode {
 *     int val;
 *     ListNode *next;
 *     ListNode(int x) : val(x), next(NULL) {}
 * };
 */
class Solution {
public:
    ListNode *detectCycle(ListNode *head) {
        if(head == NULL) return NULL;
        if(head->next == head) return head;
        ListNode* first = head;
        ListNode* second = head;
        while(second != NULL && second->next != NULL){
            first = first->next;
            second = second->next->next;
            if(first == second){
                first = head;
                while(first != second){
                    first = first->next;
                    second = second->next;
                }
                return first;
            }
        }
        return NULL;
    }
};
```

#### 判断两个链表是否相交

```c++
//
```

#### 单链表只遍历一次，要找到链表的中间位置要怎么做；



#### 找到两个链表的首个公共节点；

```c++
//ok
/**
 * Definition for singly-linked list.
 * struct ListNode {
 *     int val;
 *     ListNode *next;
 *     ListNode(int x) : val(x), next(NULL) {}
 * };
 */
class Solution {
public:
    ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) {
        if(headA == NULL || headB == NULL) return NULL;
        ListNode* first = headA;
        ListNode* second = headB;
        while(first != second){
            first = first == NULL ? headB : first->next;
            second = second == NULL ? headA : second->next;
        }
        return first;
    }
};
```

#### 二叉树的Z型遍历；

```c++
//Z型遍历
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {//BFS+deque  法二：层序遍历，奇数reverse偶数不反转；
public:
    vector<vector<int>> zigzagLevelOrder(TreeNode* root) {
        if(root == NULL) return {};
        vector<vector<int>> res;
        deque<TreeNode*> deque;
        deque.push_back(root);
        bool sw = true;
        while(!deque.empty()){
            int size = deque.size();
            vector<int> level;
            while(size--)
                if(sw == true){
                    root = deque.front();
                    deque.pop_front();
                    level.push_back(root->val);
                    if(root->left != NULL) deque.push_back(root->left);
                    if(root->right != NULL) deque.push_back(root->right);
                }
                else{
                    root = deque.back();
                    deque.pop_back();
                    level.push_back(root->val);
                    if(root->right != NULL) deque.push_front(root->right);
                    if(root->left != NULL) deque.push_front(root->left);
                }
            res.push_back(level);
            sw = !sw;
        }
        return res;        
    }
};
```

#### 二叉树的层序遍历

```c++
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {//BFS
public:
    vector<vector<int>> levelOrder(TreeNode* root) {
        if(root == NULL) return {};
        queue<TreeNode*> deq;
        deq.push(root);
        vector<vector<int>> res;
        while(!deq.empty()){
            int size = deq.size();
            vector<int> vec;
            while(size--){
                root = deq.front();
                deq.pop();
                vec.push_back(root->val);
                if(root->left != NULL) deq.push(root->left);
                if(root->right != NULL) deq.push(root->right);
            }
            res.push_back(vec);
        }    
        return res;            
    }
};
//自底向上的层序遍历
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    vector<vector<int>> levelOrderBottom(TreeNode* root) {
        if(root == NULL) return {};
        int n = getDepth(root);
        vector<vector<int>> res(n,vector<int>());
        queue<TreeNode*> queue;
        queue.push(root);
        while(!queue.empty()){
            int size = queue.size();
            vector<int> level;
            while(size--){
                root = queue.front();
                queue.pop();
                level.push_back(root->val);
                if(root->left != NULL) queue.push(root->left);
                if(root->right != NULL) queue.push(root->right);
            }
            res[--n] = level;
        }
        return res;
    }
    int getDepth(TreeNode * root){
        if(root == NULL) return 0;
        return max(getDepth(root->left),getDepth(root->right))+1;
    }
};


```



LFU leetcode 460

场景类算法题有依赖关系的进程启动管理

二分法求浮点数平方根，不得递归，精度要求0.001 

多线程打印ABCD

```c++
#
```

#### 实现两个线程交替打印AB

```c++
#include<iostream>
#include<windows.h>
#include<string>

using namespace std;

class THREAD_DATA{
public:
    int maxnum;
    string data;
    THREAD_DATA() : maxnum(0) ,data("") {}
    THREAD_DATA(int num,string str) : maxnum(num),data(str) {}
};

HANDLE cout_Mutex;
HANDLE hEvent;

DWORD WINAPI MyThread1(LPVOID lpParamter){

    THREAD_DATA *data = (THREAD_DATA *)lpParamter;
    for(int i = 0;i < data->maxnum;++i){
        WaitForSingleObject(hEvent,INFINITE);
        cout<<data->data<<"A"<<endl;
        //ReleaseMutex(cout_Mutex);
        SetEvent(hEvent);
    }
    return 0L;
};

DWORD WINAPI MyThread2(LPVOID lpParamter){

    THREAD_DATA *data = (THREAD_DATA *)lpParamter;
    for(int i = 0;i < data->maxnum;++i){
        WaitForSingleObject(hEvent,INFINITE);
        cout<<data->data<<"B"<<endl;
        //ReleaseMutex(cout_Mutex);
        SetEvent(hEvent);
    }
    return 0L;
}

int main(){

    THREAD_DATA thread_data1,thread_data2;
    thread_data1.maxnum = 5;
    thread_data1.data = "线程1----";
    thread_data2.maxnum = 5;
    thread_data2.data = "线程2----";

    cout_Mutex = CreateMutex(NULL,FALSE,NULL);
    hEvent = CreateEvent(NULL, FALSE, TRUE, NULL);

    HANDLE hThread1 = CreateThread(NULL,0,MyThread1,&thread_data1,0,NULL);
    HANDLE hThread2 = CreateThread(NULL,0,MyThread2,&thread_data2,0,NULL);
    CloseHandle(hThread1);
    CloseHandle(hThread2);
    system("pause");   
    return 0;
}
```

手写大小端转换函数 







手写socket断点续传文件

手撕智能指针

斐波那契数列 

二叉树的最大路径和、二叉树最大和的路径；

DFS、BFS

整数转化成字符串；

迭代二叉树的深度；

0-n-1中缺失的数字，两种方法；

二叉搜索树后序遍历；

IP地址字符串转换为32位整数；

两个有序数组，其中一个有足够空位，不使用额外空间排序到含空位数组中；

求二叉树两个节点的最小距离；

对大规模数据进行去重；

寻找无序整数数组中第一个缺失的正数；

对给出一个数组中的每个元素求因数个数；

二维数组回旋打印；